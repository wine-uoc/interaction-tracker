{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "# import statsmodels.api as sm\n",
    "import os\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from joblib import dump\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUILDING THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RSSI</th>\n",
       "      <th>distance</th>\n",
       "      <th>dist_&lt;_1m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12109</th>\n",
       "      <td>-55</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12110</th>\n",
       "      <td>-48</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12111</th>\n",
       "      <td>-48</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12112</th>\n",
       "      <td>-46</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12113</th>\n",
       "      <td>-46</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12114 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RSSI  distance  dist_<_1m\n",
       "0      -25       0.0          1\n",
       "1      -25       0.0          1\n",
       "2      -25       0.0          1\n",
       "3      -25       0.0          1\n",
       "4      -25       0.0          1\n",
       "...    ...       ...        ...\n",
       "12109  -55       0.8          1\n",
       "12110  -48       0.8          1\n",
       "12111  -48       0.8          1\n",
       "12112  -46       0.8          1\n",
       "12113  -46       0.8          1\n",
       "\n",
       "[12114 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataset\n",
    "data = pd.DataFrame(columns=['RSSI', 'distance'])\n",
    "\n",
    "# Reading gathered data files\n",
    "files_list = sorted(list(filter(lambda x: (\"detectedDevs\" in x), os.listdir(\".\"))))\n",
    "\n",
    "#concatenate file's data to build the dataset\n",
    "for file in files_list:\n",
    "    filename_split = file.split('_')\n",
    "    distance = float(filename_split[2]) / 100\n",
    "    df = pd.read_json('./'+file)\n",
    "\n",
    "    df.drop(['devname', 'launchpadId'], axis=1, inplace=True)\n",
    "    df.insert(loc=1, column='distance', value=np.repeat(distance, df.shape[0]))\n",
    "\n",
    "    data = data.append(df)\n",
    "\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#create the column \"dist_<_1m\" to allow performing classification\n",
    "data.insert(2, 'dist_<_1m', data['distance'].apply(lambda dist: 1 if dist < 1.0 else 0))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      RSSI  distance  dist_<_1m\n",
      "3643   -48       0.8          1\n",
      "4164   -26       0.0          1\n",
      "3585   -46       0.8          1\n",
      "8342   -27       0.0          1\n",
      "7163   -43       0.6          1\n",
      "...    ...       ...        ...\n",
      "10594  -63       3.0          0\n",
      "10595  -63       3.0          0\n",
      "10596  -64       3.0          0\n",
      "10597  -61       3.0          0\n",
      "10598  -61       3.0          0\n",
      "\n",
      "[9082 rows x 3 columns]\n",
      "1    4541\n",
      "0    4541\n",
      "Name: dist_<_1m, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#imbalanced dataset. down-sample majority class\n",
    "data_maj = data[data['dist_<_1m'] == 1]\n",
    "data_min = data[data['dist_<_1m'] == 0]\n",
    "\n",
    "data_maj_downsampled = resample(data_maj, replace=False, n_samples=data_min.shape[0], random_state=176341)\n",
    "\n",
    "data = pd.concat([data_maj_downsampled, data_min])\n",
    "print(data)\n",
    "print(data['dist_<_1m'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Mixed data')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABK8AAAOzCAYAAAB+tyWKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzde5RVdd348Q8wQnLxRjNeH0vRmSjkARPxAqgIiQWiA15ACRtsoQmEQcTFB5REvGAQYGjWJCp4QRC11MdbgoippBZpKaCEQMY8gAkjisr5/dGPs5i46gye7wyv11qs5d5nn70/c84W67323lMrk8lkAgAAAAASVDvXAwAAAADA9ohXAAAAACRLvAIAAAAgWeIVAAAAAMkSrwAAAABIlngFAAAAQLLEKwAgGUVFRfHggw/meoxqZ9asWfH1r399h9u0b98+fvGLX3wh80yaNCk6duy43WUAgM9CvAKAPdjQoUOjqKgo++eb3/xmnH/++TFnzpxcj7ZLFixYEEVFRbF8+fJcj8IOlJSUxL333rvL23fs2DEmTZq0GycCAKoT8QoA9nDHHXdczJs3L+bNmxf33XdffP3rX4/LL788li1bluvRcm7jxo25HqFGaNCgQRxwwAG5HgMAqKbEKwDYw+21116Rn58f+fn50aRJkxg0aFB8/PHH8cYbb2S3Wb9+fYwcOTJOOOGEOOaYY6K4uDjmzZsXEf8OPGeffXb84Ac/yG7/4YcfRufOnWPgwIEREbF8+fIoKiqK2bNnR+/evaN58+bRvn37eOihh3Y426pVq+KKK66I4447Lpo3bx69evWKhQsXZvd54YUXRkTE6aefHkVFRdGrV6/t7uudd96JkpKSOOaYY+LUU0+NadOmRa9evWLEiBHZbdq3bx/jx4+Pq666Klq3bh09evSIiIg5c+ZEcXFxNGvWLE488cS46qqr4oMPPsi+b+jQoXHxxRdXON6DDz4YRUVF2eXNt849/PDDcfrpp8cxxxwTF198cbzzzjsV3vfcc8/FBRdcEM2bN4+2bdvGsGHDYu3atdnXM5lMTJgwIU488cRo2bJlXHHFFfH+++/v8HPc7KOPPooRI0bEscceG61bt44bb7wxNm3aFBEREydOjDPOOGOr9wwbNmyHn+vGjRtj1KhR8c1vfjNatWoVo0aN2ir6/edtg++++270798/WrduHc2bN4/TTz89fvWrX0VERK9evWLZsmUxefLk7BWBy5cvj0wmE1deeWV06NAh+56f/exnFY61+ThPPvlkdOrUKVq0aJHd35b+8pe/RJ8+feLYY4+Nli1bRvfu3eNPf/pT9vWdfQcAwBdLvAIAsjZu3BgzZsyIunXrVniG0vDhw2PevHlx4403xuzZs+PYY4+NSy+9NJYsWRJ169aN8ePHx/PPPx933XVXRERcc801sWHDhvjpT39aYf/jxo2Lbt26xezZs6NLly4xZMiQbIz6T5lMJi6//PJ466234pZbbokZM2ZE48aNo6SkJNasWRMHH3xw9hlOM2bMiHnz5m33VrNMJhP9+vWLdevWxbRp02LKlCnxzDPPxOuvv77VtnfeeWc0btw47rnnnrj++uvjb3/7W1x22WVx3HHHxYMPPhjXXXddPPPMMzFq1KjP/PmWlZXF9OnTY/z48TFt2rQoLy+Pyy+/PDKZTEREPP/88/GDH/wgvvOd78RDDz0UN998cyxfvjz69euX3eaOO+6I22+/PYYMGZJ91tXkyZN36fh33nlnFBQUxP333x/Dhg2LadOmxdSpUyMi4rzzzot33nknXnzxxez269evj8ceeyzOPffc7e5z3Lhx8fjjj8f1118f99xzT9SvXz+mTZu2wzmuuuqqWLduXdx+++3xyCOPxJgxY+Kggw6KiH8HqEMPPTRKSkqyVwQefPDBkclkonHjxnHTTTfFI488EsOHD49Zs2bFLbfcstVnfPfdd8e4cePinnvuiXXr1sXw4cOzry9atCguuuii2HfffWPq1KnxwAMPxMUXX5yNeLvyHQAAX7AMALDH+slPfpJp2rRppkWLFpkWLVpkioqKMi1atMj87ne/y26zdOnSTGFhYeaZZ56p8N6zzz47M3To0OzyrFmzMs2aNctMmDAh841vfCPzpz/9KfvaO++8kyksLMyMHz++wj7OP//8zKBBg7LLhYWFmdmzZ2cymUxm/vz5mcLCwsyiRYuyr3/00UeZk08+OTNp0qRMJpPJvPTSS5nCwsLMO++8s8Ofc968eZnCwsLM0qVLs+vWrl2bad68eWb48OHZdaeddlrmu9/9boX3Dh48ONOtW7cK65544olMUVFRZvny5ZlM5t+fY+/evStsM3v27ExhYWF2eeLEiVvN8NZbb2UKCwszzz33XCaTyWQuuuiizI033lhhPytWrMgUFhZmXn/99Uwmk8m0bds287Of/azCNv379880bdp0h5/BaaedlunRo0eFdTfddFOmbdu22eW+fftW+D7uvvvuzPHHH5/58MMPt7nP8vLyTLNmzTL33ntvhfXnnHNOpkOHDhV+9i2Xu3Tpkpk4ceJ2Z+3QocMOX9/sN7/5TaZjx44VjtO0adPM6tWrs+t++9vfZoqKirI/w+DBgzNdunTJfPrpp9vc5658BwDAFysv1/EMAMit5s2bx/XXXx8RER988EHMmzcvhg4dGo0aNYq2bdvG4sWLI+Lfz8ba0nHHHRevvvpqdvmcc86JOXPmxC9+8YsYNGhQNG/efKtjtWzZcqvlP/zhD9uca9GiRbHffvvFUUcdlV1Xt27daN68eXamXbV48eLYf//94ytf+Up23X777RdHHHHEVtv+59yLFy+OE044ocK6448/PjKZTCxevDgOPfTQXZ7jgAMOqDDDEUccEfvvv38sXrw4TjrppFi4cGG8+uqr27xyaenSpfFf//Vf8c9//nOrz/HYY4+NJ598cqfHb9GixVbvu/XWW2P9+vXRsGHDuOCCC2LAgAHxr3/9K/bdd9+477774qyzzop69eptc3/Lli2LjRs3bjXPN7/5zXjmmWe2O0fv3r1j1KhRMXfu3Dj++OPj1FNPjVatWu10/vvuuy9mzJgRK1asiA0bNsQnn3yy1dVQBQUFFZ6vdeCBB0Ymk4nVq1fHIYccEq+99lq0bds2atfe9g0IO/sOmjZtutM5AYCqJV4BwB7uS1/6UoWg0rRp0/jDH/4Qt9xyS7Rt23a778tkMlGrVq3scnl5ebz++utRp06dWLp0aZXMtuX+t3fcyuxrW/bee+/PvM9atWptFVE++eSTXdrHlu/btGlTfP/734+uXbtutd2Xv/zl7K1tn+fn39mxIyLatWsXX/7yl+PBBx+MVq1axWuvvZYNmzvyWefp1q1btG3bNp599tl44YUX4vvf/3506NAhxo0bt933PProozF69OgYNGhQtGrVKho2bBiPPfZYjB8/vsJ2e+211zbfv/mz29m8O/sOAIAvnmdeAQBbqVOnTmzYsCEiIo4++uiIiFiwYEGFbf74xz9WuCrqqquuitq1a8fUqVPjoYceit/97ndb7XfLK7UiIl555ZU48sgjtznD0UcfHWvXrq1wldXGjRtj4cKF2ePWrVs3IiqGiW056qijYs2aNfH3v/89u+5f//rXLkW2o446Kl566aUK61588cWoVatWdo7GjRvHqlWrKmyzredprVmzpsLDw99+++147733okmTJhER0axZs1i8eHF85Stf2epPgwYNolGjRnHggQfGyy+/XGG//7m8PVs+lDzi399HQUFBNGzYMCIiateuHd27d48ZM2bEfffdFy1btsx+/9ty+OGHx1577bXV8V955ZWdzlJQUBDdunWLG264IcaMGRMPP/xwrF+/PiL+HaA+/fTTCtsvWLAgmjZtGt/73veiWbNm8dWvfjVWrFixSz/3lr7xjW/E/Pnzt3vO7Ow7AAC+eOIVAOzhPv744ygrK4uysrJYtmxZTJs2LebNm5f97XCHH354dOrUKa6++up49tlnY8mSJXHNNdfEokWLok+fPhHx79+st/kqmFatWsWPfvSjGDly5Fa/Se/++++Phx9+ON5+++34+c9/Hq+++mr07t17m3OdcMIJ0bx58xg0aFD88Y9/jDfffDOGDBkSH330Ufa3AB5yyCFRu3btmDNnTqxevTrWrVu3zX2ddNJJ8bWvfS1+8pOfxJ///Of429/+FkOGDIk6ders9KqhPn36xOuvvx5jx46NJUuWxNy5c+Oaa66JLl26xCGHHJLd/1tvvRV33XVXLFu2LO6777549NFHt9rX3nvvHcOGDYu//OUvsXDhwhg6dGgUFhbGSSedFBERAwYMiKeeeiquvfba+Otf/xrLli2LuXPnxvDhw+PDDz+MiIiSkpK44447Yvbs2bF06dIoLS2N559/foc/w2Z//etfY9KkSfH222/Hww8/HHfcccdWvyWxe/fu8dZbb8WMGTPi/PPP3+H+6tevHxdccEFMmDAhnnrqqXjrrbfihhtuiLfeemuH7xs9enTMmTMnli1bFosWLYrHH388Dj744GwcOuyww+Lll1+OlStXxpo1a2LTpk1xxBFHxJtvvhlPPvlkLFu2LKZOnRqPP/74Lv3cW7rkkkvi73//ewwePDgWLlwYy5Yti0cffTQb3HblOwAAvljiFQDs4RYsWBBt2rSJNm3aRJcuXWL69OkxaNCg6Nu3b3abMWPGRJs2beLHP/5xdO3aNV5++eW45ZZbokmTJvH3v/89rr766hgyZEj2eUDf+973omXLlvGjH/0oPv744+x+Bg0alH2O0ubf3LetZ2NF/PvWrptvvjmOPPLI6Nu3b3Tv3j3+7//+L0pLS7PPNPryl78cP/rRj+KXv/xltGnTJn7wgx9sd1+TJ0+OvffeOy688MLo27dvtGvXLo444ojtPs9ps6997WsxZcqUeOmll6Jr164xZMiQOOWUU+Lqq6/ObnPSSSfFwIED49Zbb42uXbvGH/7wh7j88su32ld+fn6cd955MWDAgOjRo0fUq1cvbr755mxAO+GEE2Lq1Knx5ptvRs+ePeOss86KsWPHRoMGDSIv799Pe/jud78bvXr1irFjx8bZZ58dr7766jaPtS29evWKlStXRrdu3eKnP/1pXHDBBVvFq4KCgjj11FPjS1/6Upx55pk73efgwYOjQ4cOMWTIkDj33HNj3bp1ceGFF+7wPZlMJq699tro3LlzXHTRRbFhw4a47bbbsp9D//79Y/369dGpU6c48cQTY+XKlXH++edH165dY/jw4XH22WfHn//85+jfv/8u/dxbKioqijvvvDPWrFkTvXr1iq5du0ZpaWnUqVMnInbtOwAAvli1Mv/5sAMAgCq2fPnyOP3002PatGlbPfg9V9avXx+nnHJKDBw4MHr16rXbjzdp0qR46KGH4oknntjtx6qs7t27x3//93/H//zP/+R6FAAAD2wHAPYMTz31VOTl5cWRRx4Za9asicmTJ0etWrV26eqiPcXq1avjqaeeitdffz1+9rOf5XocAICIEK8AgD3Ehx9+GDfffHOsWLEi9t577/jGN74R06dP9xvktnDSSSfFvvvuGyNGjIjDDz881+MAAESE2wYBAAAASJgHtgMAAACQLPEKAAAAgGSJVwAAAAAkS7wCAAAAIFniFQAAAADJEq8AAAAASJZ4BQAAAECyxCsAAAAAkiVeAQAAAJAs8QoAAACAZIlXAAAAACRLvAIAAAAgWeIVAAAAAMkSrwAAAABIlngFAAAAQLLEKwAAAACSJV4BAAAAkCzxCgAAAIBkiVcAAAAAJEu8AgAAACBZ4hUAAAAAyRKvAAAAAEiWeAUAAABAssQrAAAAAJIlXgEAAACQLPEKAAAAgGSJVwAAAAAkS7wCAAAAIFniFQAAAADJEq8AAAAASJZ4BQAAAECyxCsAAAAAkiVeAQAAAJAs8QoAAACAZIlXAAAAACRLvAIAAAAgWeIVAAAAAMkSrwAAAABIlngFAAAAQLLEKwAAAACSJV4BAAAAkCzxCgAAAIBkiVcAAAAAJEu8AgAAACBZ4hUAAAAAyRKvAAAAAEiWeAUAAABAssQrAAAAAJIlXgEAAACQLPEKAAAAgGSJVwAAAAAkS7wCAAAAIFniFQAAAADJEq8AAAAASJZ4BQAAAECyxCsAAAAAkiVeAQB8TiNHjoybb765yvfbvn37mD9//i5tO2vWrOjRo0eVzwAAkArxCgDgP7Rv3z6aNWsWa9asqbC+a9euUVRUFMuXL4+IiNGjR8fll1+eixE/l0mTJsXgwYNzPQYAwGciXgEAbMOhhx4av/vd77LLb7zxRnz44Yc5nAgAYM8kXgEAbEPXrl1j9uzZ2eXZs2fH2WefXWGboUOHxvjx4yMi4pe//GWcd9558cknn0RExPTp0+M73/lOfPTRR7Fp06b45S9/GR06dIjWrVvHD3/4w3jvvfcq7Pu0006L1q1bx5QpU3Y419q1a+PSSy+NY489Nrp37x7Lli2r8Po111wTp5xyShx77LFRXFwcCxYsiIiIuXPnxq233hqPPvpotGzZMs4666yIiJg5c2aceeaZ0bJlyzj99NPjnnvu+ZyfGADA7iFeAQBsQ4sWLWL9+vWxZMmS+PTTT+ORRx7JBp9tueSSS2KvvfaKKVOmxNKlS2P8+PFx4403Rr169eKOO+6IJ598Mu6666549tlnY999943Ro0dHRMTixYvj6quvjhtuuCGeffbZeO+99+Ldd9/d7nFGjx4d9erVi3nz5sW1114bM2fOrPD6McccE7Nnz44XX3wxOnfuHD/84Q/jo48+inbt2kXfvn3jzDPPjFdeeSUeeuihiIho3Lhx3HrrrfHyyy/H2LFjY+zYsfHaa69VwScIAFA1xCsAgO3YfPXVc889F0ceeWQceOCB2922du3acf3118edd94Zl112WVxyySXx9a9/PSIi7r333rjiiivioIMOirp160a/fv3if//3f+OTTz6Jxx57LE499dRo1apV1K1bN374wx9G7drb/p9on376aTz++OMxYMCAqF+/fhQWFsY555yz1cz7779/5OXlRUlJSWzcuDHefvvt7c596qmnxuGHHx61atWK448/Pk4++eTs1VoAACnIy/UAAACp6tq1a1x00UWxfPny6Nq16063P+yww6J169YxZ86cuPDCC7PrV65cGZdffnmFKFW7du1YvXp1rFq1Kg466KDs+vr168d+++23zf2vWbMmPvnkkzj44IOz6w455JAK25SWlsaMGTNi1apVUatWrVi/fn2sXbt2uzPPmTMnbr755li6dGls2rQpPvzwwygsLNzpzwoA8EVx5RUAwHYceuihcdhhh8WcOXPiW9/61k63nzNnTrzyyitx4oknxg033JBdf9BBB8Vtt90WCxYsyP5ZuHBhHHjggVFQUFDhNsENGzZUeB7Wlg444IDIy8uLf/zjH9l1W/7zggUL4rbbbosJEybESy+9FAsWLIhGjRpFJpOJiIhatWpV2N/GjRtjwIABUVJSEs8991wsWLAg2rVrl90eACAF4hUAwA6MGTMmpk6dGvXr19/hdmvWrIkRI0bEmDFj4rrrrounn3465syZExERPXr0iAkTJsSKFSuy2z755JMREXHGGWfEM888EwsWLIiNGzfGxIkTY9OmTds8Rp06daJjx44xefLk2LBhQyxevDgeeOCB7Ovl5eVRp06dOOCAA+KTTz6JyZMnx/r167OvN27cOFasWJHd/8aNG2Pjxo3ZKDZnzpx47rnnPv+HBQCwG4hXAAA7cPjhh8cxxxyz0+1GjhwZ7du3j1NOOSX233//GDNmTIwYMSLWrl0b3/3ud6N9+/ZRUlISLVu2jPPOOy/+/Oc/R0TE0UcfHSNHjozBgwdH27ZtY5999qlwG+G2jvPBBx/EySefHEOHDo3i4uLsa23atIl27drFGWecEe3bt4969epVuMWwU6dOERHRunXrOOecc6Jhw4Zx5ZVXxsCBA6NVq1bx29/+Ntq3b/95PyoAgN2iVsZ14QAAAAAkypVXAAAAACRLvAIAAAAgWeIVAAAAAMkSrwAAAABIlngFAAAAQLLycj3Arli7tjw2bfJLEbelceOGsXr1+lyPQTXl/KEynD9UhvOHynD+UBnOHyrD+UNlOH+2r3btWrH//g22+3q1iFebNmXEqx3w2VAZzh8qw/lDZTh/qAznD5Xh/KEynD9UhvPn83HbIAAAAADJEq8AAAAASJZ4BQAAAECyxCsAAAAAkiVeAQAAAJAs8QoAAACAZIlXAAAAACRLvAIAAAAgWeIVAAAAAMkSrwAAAABIlngFAAAAQLLEKwAAAACSJV4BAAAAkCzxCgAAAIBkiVcAAAAAJEu8AgAAACBZ4hUAAAAAyRKvAAAAAEiWeAUAAABAssQrAAAAAJIlXgEAAACQLPEKAAAAgGSJVwAAAAAkS7wCAAAAIFniFQAAAADJEq8AAAAASJZ4BQAAAECyxCsAAAAAkiVeAQAAAJAs8QoAAACAZIlXAAAAACRLvAIAAAAgWeIVAAAAAMkSrwAAAABIVl6uB9hTdevWJZYsWZTrMbKaNDk6Zs58ONdjsIucPwAAAOwpxKscqar/o19S0jNKS6dXyb6oPpw/AAAA7CncNggAAABAssQrAAAAAJIlXgEAAACQLPEKAAAAgGSJVwAAAAAkS7wCAAAAIFniFQAAAADJEq8AAAAASJZ4BQAAAECyxCsAAAAAkiVeAQAAAJAs8QoAAACAZIlXAAAAACQrL9cDVDePPDIr9ttvv1yPkXXJJZfE/PlP53qMrPfeey++/e3iXI8BAAAA1BDi1Wd0//33R2np9FyPkZWf3yjKytbleoyskpKe4hUAAABQZdw2CAAAAECyxCsAAAAAkiVeAQAAAJAs8QoAAACAZIlXAAAAACRLvAIAAAAgWeIVAAAAAMkSrwAAAABIlngFAAAAQLLEKwAAAACSJV4BAAAAkCzxCgAAAIBkiVcAAAAAJCsv1wNURyUlPXM9QrIaNGiQ6xEAAACAGkS8+oxKS6fneoQKSkp6JjcTAAAAQFVx2yAAAAAAyRKvAAAAAEiWeAUAAABAssQrAAAAAJIlXgEAAACQLPEKAAAAgGSJVwAAAAAkS7wCAAAAIFniFQAAAADJEq8AAAAASJZ4BQAAAECyxCsAAAAAkiVeAQAAAJCsvFwPsKfq1q1LLFmyqEr21aLF1yq9jyZNjo6ZMx+ugmkAAAAAqo54lSNVFYry8xtFWdm6KtkXAAAAQGrcNggAAABAssQrAAAAAJIlXgEAAACQLPEKAAAAgGSJVwAAAAAkS7wCAAAAIFniFQAAAADJEq8AAAAASJZ4BQAAAECyxCsAAAAAkpWX6wH4fAoK9tlq3apV7+dgEgAAAIDdx5VX1dCW4eqWW27Z5noAAACAmkC8qsZWrXo/+vbt64orAAAAoMYSr6qpceMm7HAZAAAAoCYQr6qpwYMH7nAZAAAAoCYQr6qxgoJ94tZbb/WsKwAAAKDGEq+qoS2fcXXppZducz0AAABATZCX6wH4fDaHqvz8RlFWti7H0wAAAADsHq68AgAAACBZ4hUAAAAAyRKvAAAAAEiWeAUAAABAssQrAAAAAJIlXgEAAACQLPEKAAAAgGTlVXYHU6ZMiUceeSTq1KkTmUwm+vbtG9/+9rcjImLDhg0xbNiweO2116JOnTrxk5/8JE477bRKD01EQcE+W61bter9HEwCAAAAsPtUOl5ddNFFcdlll0VExD//+c8488wz4+STT4599903fv3rX0eDBg3iiSeeiKVLl8aFF14Yjz/+eDRo0KDSg+/JtgxXAwYMiIkTJ2bXC1gAAABATVLp2wYbNWqU/ecPPvggatWqFZs2bYqIiEcffTQuuOCCiIj46le/Gs2aNYu5c+dW9pD8f6tWvR8///nPBSsAAACgxqr0lVcREXfffXdMnTo13n333bj22mtj//33j4iIlStXxqGHHprd7uCDD4533333M++/ceOGVTFmjTJgwIDIz/93OMzPb5S9AmvzOthVzhkqw/lDZTh/qAznD5Xh/KEynD9UhvPn89lpvDrnnHNi5cqV23xt/vz5UadOnejRo0f06NEj3njjjRg8eHCceOKJ2YBVFVavXh+bNmWqbH81wcSJE+PKK6+J/PxGUVa2LnvrYFnZuhxPRnXjnOHz2vz3D3wezh8qw/lDZTh/qAznD5Xh/Nm+2rVr7fDCpZ3GqwceeGCXD1ZUVBQFBQXx4osvxhlnnBGHHHJIrFixIg444ICIiPjHP/4RrVu33uX9sWMFBftUeOYVAAAAQE1T6WdeLVmyJPvP77zzTvz1r3+No446KiIiOnXqFPfee29ERCxdujQWLlwYbdu2rewh93hbPuNqy3Dl2VcAAABATVPpZ15NnDgxFi9eHHl5eVGnTp248soro0mTJhER0adPnxg6dGh07NgxateuHaNHj46GDT2/qipsDlUuOwQAAABqskrHq5///Ofbfa1+/fpuaQMAAADgc6v0bYMAAAAAsLuIVwAAAAAkS7wCAAAAIFniFQAAAADJEq8AAAAASJZ4BQAAAECy8nI9AJ9PQcE+W61bter9HEwCAAAAsPu48qoa2jJc3XLLLdtcDwAAAFATiFfV2KpV70ffvn1dcQUAAADUWOJVNTVu3IQdLgMAAADUBOJVNTV48MAdLgMAAADUBOJVNVZQsE/ceuutnnUFAAAA1FjiVTW05TOuLr300m2uBwAAAKgJ8nI9AJ/P5lCVn98oysrW5XgaAAAAgN3DlVcAAAAAJEu8AgAAACBZ4hUAAAAAyRKvAAAAAEiWeAUAAABAssQrAAAAAJIlXgEAAACQrLxcD8DnU1Cwz1brVq16PweTAAAAAOw+rryqhrYMV7/61a+2uR4AAACgJhCvqrFVq96PPn36uOIKAAAAqLHcNlhNjR8/aavlK67on6NpgOqkW7cusWTJolyPkdWkydExc+bDuR4DAABIlHhVTV1xRf+48MLeFZYBdkVVhaKSkp5RWjq9SvYFAACwPW4brMYKCvaJX//61551BQAAANRY4lU1tOUzri655JJtrgcAAACoCdw2WINAHwcAACAASURBVE1tDlX5+Y2irGxdjqcBAAAA2D1ceQUAAABAssQrAAAAAJIlXgEAAACQLPEKAAAAgGSJVwAAAAAkS7wCAAAAIFniFQAAAADJEq+qqWHDBsdhh+VHrVq14rDD8mPYsMG5HgkAAACgyolX1dCwYYPj9ttLY8SIUVFeXh4jRoyK228vFbAAAACAGke8qobuvHNqjBw5Oi67rF/Ur18/LrusX4wcOTruvHNqrkcDAAAAqFLiVTW0ceNH0bt3SYV1vXuXxMaNH+VoIgAAAIDdQ7yqhurWrRdTp5ZWWDd1amnUrVsvRxMBAAAA7B7iVTXUq1fvGD16ZEyZMjk++OCDmDJlcowePTJ69eqd69EAAAAAqlRergfgsxs7dlxERIwZc3WMGjU86tatFxdfXJJdDwAAAFBTiFfV1Nix42Ls2HGRn98oysrW5XocAAAAgN3CbYMAAAAAJEu8AgAAACBZ4hUAAAAAyRKvAAAAAEiWeAUAAABAssQrAAAAAJIlXgEAAACQLPEKAAAAgGSJVwAAAAAkS7wCAAAAIFl5uR4A9iT9+38/ysvLcz1GBSUlPXM9QlaDBg1i0qTbcj0GAAAACRGv4AtUXl4epaXTcz1GVn5+oygrW5frMbJSCmkAAACkwW2DAAAAACRLvAIAAAAgWeIVAAAAAMkSrwAAAABIlngFAAAAQLLEKwAAAACSJV4BAAAAkCzxCgAAAIBkiVcAAAAAJEu8AgAAACBZ4lU1NWzY4DjssPyoVatWHHZYfgwbNjjXIwEAAABUOfGqGho2bHDcfntpjBgxKsrLy2PEiFFx++2lAhYAAABQ44hX1dCdd06NkSNHx2WX9Yv69evHZZf1i5EjR8edd07N9WgAAAAAVSov1wPw2W3c+FH07l1SYV3v3iUxatTwHE3EriouLo7585/O9RjJKi4uzvUIAAAAJEa8qobq1q0XU6eWxmWX9cuumzq1NOrWrZfDqdgVs2bNitLS6bkeIys/v1GUla3L9RhZJSU9o3Pn7rkeAwAAgIS4bbAa6tWrd4wePTKmTJkcH3zwQUyZMjlGjx4ZvXr1zvVoAAAAAFXKlVfV0Nix4yIiYsyYq2PUqOFRt269uPjikux6AAAAgJpCvKqmxo4dF2PHjkvuti8AAACAquS2QQAAAACSJV4BAAAAkCzxCgAAAIBkiVcAAAAAJEu8AgAAACBZ4hUAAAAAyRKvAAAAAEiWeFVNzZo1I9q1ax116tSJdu1ax6xZM3I9EgAAAECVy8v1AHx2s2bNiGuv/WlMmDA5Onf+Vvz2t4/HwIH9IiKiuPjcHE8HAAAAUHVceVUNTZgwLiZMmBxt2rSLvfbaK9q0aRcTJkyOCRPG5Xo0AAAAgColXlVDb775RrRufWKFda1bnxhvvvlGjiYCAAAA2D3Eq2qosLAoXnjh+QrrXnjh+SgsLMrRRAAAAAC7h3hVDQ0cODgGDuwX8+bNjY8//jjmzZsbAwf2i4EDB+d6NAAAAIAq5YHt1dDmh7IPH/7j6N79rCgsLIrhw//Hw9oBAACAGke8qqaKi8+N4uJzIz+/UZSVrcv1OAAAAAC7hdsGAQAAAEiWeAUAAABAssQrAAAAAJIlXgEAAACQLPEKAAAAgGSJVwAAAAAkS7wCAAAAIFl5uR6Az6egYJ+t1q1a9X4OJgEAAADYfVx5VQ1tGa569OixzfUAAAAANYF4VY2tWvV+TJ8+3RVXAAAAQI3ltsFq6pxzum+1/MAD9+doGgD2FN26dYklSxbleoysJk2OjpkzH871GAAA7EbiVTX1wAP3x623llZYBoDdrapCUUlJzygtnV4l+wIAoGZz22A1VlCwT/Ts2dOzrgAAAIAaS7yqhrZ8xtXdd9+9zfUAAAAANYHbBqupzaEqP79RlJWty/E0AAAAALuHK68AAAAASJZ4BQAAAECyxCsAAAAAkiVeAQAAAJAs8QoAAACAZIlXAAAAACRLvAIAAAAgWeIVAAAAAMkSrwAAAABIlngFAAAAQLLEKwAAAACSJV4BAAAAkCzxCgAAAIBkiVcAAAAAJEu8AgAAACBZ4hUAAAAAyRKvAAAAAEiWeAUAAABAssQrAAAAAJIlXgEAAACQLPEKAAAAgGSJVwAAAAAkS7wCAAAAIFniFQAAAADJEq8AAAAASJZ4BQAAAECyxCsAAAAAkiVeAQAAAJAs8QoAAACAZIlXAAAAACRLvAIAAAAgWeIVAAAAAMkSrwAAAABIlngFAAAAQLLEKwAAAACSJV4BAAAAkCzxCgAAAIBkVVm8euGFF6Jp06Zx1113Zddt2LAhBg4cGB07doxOnTrF73//+6o6HAAAAAB7gLyq2Mn69etj3Lhx0a5duwrrf/3rX0eDBg3iiSeeiKVLl8aFF14Yjz/+eDRo0KAqDgsAAABADVclV15dd9110adPn9h///0rrH/00UfjggsuiIiIr371q9GsWbOYO3duVRwSAAAAgD1ApePVnDlz4v33349OnTpt9drKlSvj0EMPzS4ffPDB8e6771b2kAAAAADsIXZ62+A555wTK1eu3OZrjz32WNx0003xm9/8psoH21Ljxg136/6ru/z8Rrkegc+gpKRnrkdIVsOGDZ3PO9CjR49Yv359rseoIKXzuWHDhnH33Xfnegw+A/++73nat28fb7zxRq7HyCoqKoqnn34612OQA/7+oTKcP1SG8+fz2Wm8euCBB7b72oIFC6KsrCzOPffciIhYu3Zt/P73v4/33nsv+vXrF4ccckisWLEiDjjggIiI+Mc//hGtW7f+zEOuXr0+Nm3KfOb37Qny8xtFWdm6XI/BLiotnZ7rESooKemZ3EzO5+1bv359Ut9Xan//lJT0TGoeds73tee5994Hq2Q/VfnfL+fhnie1/35RvTh/qAznz/bVrl1rhxcuVeqB7ccdd1w8//zz2eWhQ4dGs2bN4qKLLoqIiE6dOsW9994bxxxzTCxdujQWLlwYN910U2UOCQAAAMAepEoe2L49ffr0iffffz86duwYffv2jdGjR0fDhm4BBAAAAGDXVOrKq/903XXXVViuX79+TJw4sSoPAQAAAMAeZLdeeQUAAAAAlSFeAQAAAJAs8QoAAACAZIlXAAAAACRLvAIAAAAgWeIVAAAAAMkSrwAAAABIVl6uB+DzKSjYZ6t1q1a9n4NJAAAAAHYfV15VQ5vDVe3atePJJ5+M2rVrV1gPAAAAUFO48qqaql27drz77nuRn98o3n33vTjooP1i06ZNuR4LAAAAoEq58qqauu++2TtcBgAAAKgJxKtq6rzzzt7hMgAAAEBNIF5VU5s2bYqDDtovnnrqKbcMAgAAADWWeFUNbf6tgps2bYoOHTpkw5XfNggAAADUNB7YXk1tDlX5+Y2irGxdjqcBAAAA2D1ceQUAAABAssQrAAAAAJIlXgEAAACQLPEKAAAAgGSJVwAAAAAkS7wCAAAAIFniFQAAAADJEq+qqVmzZkS7dq2jTp060a5d65g1a0auRwIAAACocnm5HoDPbtasGXHttT+NCRMmR+fO34rf/vbxGDiwX0REFBefm+PpAAAAAKqOK6+qoQkTxsWECZOjTZt2sddee0WbNu1iwoTJMWHCuFyPBgAAAFClXHlVDb355hvRuvWJFda1bn1ivPnmGzmaCAAAIF3dunWJJUsW5XqMrCZNjo6ZMx/O9RhQbYhX1VBhYVG88MLz0aZNu+y6F154PgoLi3I4FQAAQJqqKhSVlPSM0tLpVbIvYNe5bbAaGjhwcAwc2C/mzZsbH3/8ccybNzcGDuwXAwcOzvVoAAAAAFXKlVfV0OaHsg8f/uPo3v2sKCwsiuHD/8fD2gEAAIAaR7yqpoqLz43i4nMjP79RlJWty/U4AAAAALuF2wYBAAAASJZ4BQAAAECyxCsAAAAAkiVeAQAAAJAs8QoAAACAZIlXAAAAACRLvAIAAAAgWeIVAAAAAMkSrwAAAABIlngFAAAAQLLycj0AALumuLg45s9/OtdjJKu4uDjXIyStf//vR3l5ea7HqKCkpGeuR8hq0KBBTJp0W67HAHagW7cusWTJolyPkdWkydExc+bDuR4DYI8gXgFUE7NmzYrS0um5HiMrP79RlJWty/UYWSUlPaNz5+65HiNZ5eXlzp8dSCmkAdtWVaGopKRnUn8fArBzbhsEAAAAIFniFQAAAADJEq8AAAAASJZ4BQAAAECyxCsAAAAAkiVeAQAAAJAs8QoAAACAZIlXAAAAACRLvAIAAAAgWeIVAAAAAMkSrwAAAABIlngFAAAAQLLEKwAAAACSlZfrAQAASFv//t+P8vLyXI9RQUlJz1yPkNWgQYOYNOm2XI8BADWWeAUAwA6Vl5dHaen0XI+RlZ/fKMrK1uV6jKyUQhoA1ERuGwQAAAAgWeIVAAAAAMkSrwAAAABIlngFAAAAQLLEKwAAAACSJV4BAAAAkCzxCgAAAIBkiVcAAAAAJEu8AgAAACBZ4hUAAAAAyRKvAAAAAEiWeAUAAABAssQrAAAAAJKVl+sBgM+uW7cusWTJoirZV4sWX6v0Ppo0OTpmzny4CqYBdpfi4uKYP//pXI+RrOLi4lyPADVW//7fj/Ly8lyPUUFJSc9cj5DVoEGDmDTptlyPAZA08QqqoaoKRfn5jaKsbF2V7AtI26xZs6K0dHqux8hK7e+fkpKe0blz91yPATVSeXm5v392IKWQBpAqtw0CAAAAkCzxCgAAAIBkiVcAAAAAJEu8AgAAACBZ4hUAAAAAyRKvAAAAAEiWeAUAAABAssQrAAAAAJIlXgEAAACQLPEKAAAAgGSJVwAAAAAkS7wCAAAAIFniFQAAAADJysv1AADsupKSnrkeIVkNGjTI9QgAAMBuIF4BVBOlpdNzPUIFJSU9k5sJAACoedw2CAAAAECyxCsAAAAAkiVeAQAAAJAs8QoAAACAZIlXAAAAACRLvAIAAAAgWeIVAAAAAMkSrwAAAABIlngFAAAAQLLEKwAAAACSJV4BAAAAkCzxCgAAAIBkiVcAAAAAJCsv1wMAAJC24uLimD//6VyPkazi4uJcj5A058+OOX8Adk68AgBgh2bNmhWlpdNzPUZWfn6jKCtbl+sxskpKekbnzt1zPUaynD875vwB2Dm3DQIAAACQLPEKAAAAgGSJVwAAAAAkS7wCAAAAIFniFQAAAADJEq8AAAAASJZ4BQAAAECyxCsAAAAAkiVeAQAAAJAs8QoAAACAZIlXAAAAACRLvAIAAAAgWeIVAAAAAMkSrwAAAABIlngFAAAAQLLEKwAAAACSJV4BAAAAkCzxCgAAAIBkiVcAAAAAJEu8AgAAACBZ4hUAAAAAyRKvAAAAAEiWeAUAAABAssQrAAAAAJIlXgEAAACQLPEKAAAAgGSJVwAAAAAkS7wCAAAAIFl5uR4AAAAAIFXdunWJJUsW5XqMrCZNjo6ZMx/O9RhfKPEKAAAAYDuqKhSVlPSM0tLpVbKvPY3bBgEAAABIlngFAAAAQLLEKwAAAPh/7d19kJX1ff/h9z6ICQtVsVvKaqyNY8RRp1g1TKqoEB1JAoQHq8aHwVmjjsY4sbEBQtWEaBFrRisxjulIoDYmGhFMjFq0GlExJLTxoWpTg5JYFhSQjATUVfb8/kjdXxlQFs+B8124rhknu+fc3Ofj7mfI8cV9L0CxxCsAAAAAiiVeAQAAAFAs8QoAAACAYolXAAAAABRLvAIAAACgWOIVAAAAAMVqrvYEkydPzqJFi7LXXnslSUaOHJkLLrggSfLGG29kypQpefbZZ9PU1JRJkyZl+PDh1b4kAAAAALuIquNVkpx33nk588wzN3v8lltuSUtLSx544IEsW7YsZ5xxRhYsWJCWlpZavCwAAAAAO7ntetvgfffdl9NOOy1Jsv/+++fQQw/NwoULt+dLAgAAALATqUm8+u53v5vRo0fnwgsvzNKlS7sf7+joyD777NP9+aBBg7Jy5cpavCQAAAAAu4Ct3jY4bty4dHR0bPG5RYsW5ZJLLklra2saGxszf/78fP7zn8+DDz6Ypqammg259979anaunVFra/96j0AvZn+ohv3pXdrbT6/3CMXq16+ffd4K+/Pe7M/Wlfb1MQ/V8P2iGvbng9lqvJo3b977Pj9w4MDuj8eOHZvp06dn5cqV2WeffdLW1pbly5dnwIABSZIVK1Zk6NCh2zzkmjW/T1dXZZt/3a6gtbV/Vq1aV+8x6KXsD9WyP73HrFm31XuETbS3n17cTPb5vZX2vbI/vU9JX58S3/+UNg/vz/eLatifLWtsbHjfC5eqvm3wlVde6f740UcfTWNjY3fQGjlyZG6//fYkybJly/LMM89k2LBh1b4kAAAAALuIqv+2wUmTJmXNmjVpaGhIv379ctNNN6W5+Q+nPeecczJ58uSceOKJaWxszLRp09Kvn1sAAQAAAOiZquPV7Nmz3/O5vn375oYbbqj2JQAAAADYRdXkbxsEAAAAgO1BvAIAAACgWOIVAAAAAMUSrwAAAAAolngFAAAAQLHEKwAAAACKJV4BAAAAUCzxCgAAAIBiiVcAAAAAFEu8AgAAAKBY4hUAAAAAxRKvAAAAACiWeAUAAABAscQrAAAAAIolXgEAAABQLPEKAAAAgGKJVwAAAAAUS7wCAAAAoFjiFQAAAADFEq8AAAAAKJZ4BQAAAECxxCsAAAAAiiVeAQAAAFAs8QoAAACAYolXAAAAABSrud4DALBjTZgwOkuXvlCTcw0ZMrjqcxxwwIGZO/fHNZgGANjZfPGL52b9+vX1HmMT7e2n13uEbi0tLZk585/qPQZsd+IVwC6mVqGotbV/Vq1aV5NzAQBsyfr16zNr1m31HqNbae9/SgppsD25bRAAAACAYolXAAAAABRLvAIAAACgWOIVAAAAAMUSrwAAAAAolngFAAAAQLHEKwAAAACKJV4BAAAAUCzxCgAAAIBiiVcAAAAAFEu8AgAAAKBY4hUAAAAAxRKvAAAAAChWc70HAAAAdm7t7afXe4RitbS01HsEgOKJVwAAwHYza9Zt9R5hE+3tpxc3EwDvz22DAAAAABRLvAIAAACgWOIVAAAAAMUSrwAAAAAolngFAAAAQLHEKwAAAACKJV4BAAAAUCzxCgAAAIBiiVcAAAAAFEu8AgAAAKBY4hUAAAAAxRKvAAAAACiWeAUAAABAsZrrPQAA0HtMmDA6S5e+UJNzDRkyuOpzHHDAgZk798c1mAYAgFKJVwBAj9UqFLW29s+qVetqci4AAHZubhsEAAAAoFjiFQAAAADFEq8AAAAAKJZ4BQAAAECxxCsAAAAAiiVeAQAAAFAs8QoAAACAYolXAAAAABRLvAIAAACgWOIVAAAAAMUSrwAAAAAolngFAAAAQLHEKwAAAACKJV4BAAAAUCzxCgAAAIBiiVcAAAAAFEu8AgAAAKBY4hUAAAAAxRKvAAAAACiWeAUAAABAscQrAAAAAIolXgEAAABQLPEKAAAAgGKJVwAAAAAUS7wCAAAAoFjiVS81Zcql2Xff1jQ0NGTffVszZcql9R4JAAAAoObEq15oypRLM3v2rEydekXWr1+fqVOvyOzZswQsAAAAYKcjXvVCt946J5dfPi0XXHBR+vbtmwsuuCiXXz4tt946p96jAQAAANRUc70HYNt1dr6ViRPbN3ls4sT2XHHFV+s0EQAAQO2NHz8+ixY9VO8xijV+/Ph6jwA7hHjVC/Xps3vmzJmVCy64qPuxOXNmpU+f3es4FQAAQG3dddddmTXrtnqP0a21tX9WrVpX7zG6tbefnlGjTq73GLDduW2wFzrrrImZNu3y3HTTt7Jhw4bcdNO3Mm3a5TnrrIn1Hg0AAACgplx51QtNn35tkuSqq76eK674avr02T1nn93e/TgAAADAzkK86qWmT78206dfW9xlqwAAAAC15LZBAAAAAIolXgEAAABQLPEKAAAAgGKJVwAAAAAUS7wCAAAAoFjiFQAAAADFEq8AAAAAKJZ4BQAAAECxxCsAAAAAiiVeAQAAAFCs5noPAADArmHChNFZuvSFmpxryJDBVZ/jgAMOzNy5P67BNACU6ItfPDfr16+v9xibaG8/vd4jdGtpacnMmf9U7zF6RLwCAGCHqFUoam3tn1Wr1tXkXADsvNavX59Zs26r9xjdSvv/r5JC2ta4bRAAAACAYolXAAAAABRLvAIAAACgWOIVAAAAAMUSrwAAAAAolngFAAAAQLHEKwAAAACKJV4BAAAAUCzxCgAAAIBiiVcAAAAAFEu8AgAAAKBY4hUAAAAAxRKvAAAAAChWc70HAAAA2JoJE0Zn6dIXanKuIUMGV32OAw44MHPn/rgG0wCwNeIVAABQvFqFotbW/lm1al1NzgXAjuG2QQAAAACKJV4BAAAAUCzxCgAAAIBiiVcAAAAAFEu8AgAAAKBY4hUAAAAAxRKvAAAAACiWeAUAAABAscQrAAAAAIolXgEAAABQLPEKAAAAgGKJVwAAAAAUS7wCAAAAoFjiFQAAAADFEq8AAAAAKJZ4BQAAAECxxCsAAAAAiiVeAQAAAFAs8QoAAACAYolXAAAAABRLvAIAAACgWOIVAAAAAMUSrwAAAAAolngFAAAAQLGaa3GSW2+9Nd/73vey2267pampKfPnz0+SvPHGG5kyZUqeffbZNDU1ZdKkSRk+fHgtXhIAAACAXUDV8WrBggW5//77c+edd6Zfv35ZtWpV93O33HJLWlpa8sADD2TZsmU544wzsmDBgrS0tFT7sru8IUMOTkfH8u7P29r2yZNPPl/HiQAAAABqr+rbBmfNmpWLLroo/fr1S5K0trZ2P3fffffltNNOS5Lsv//+OfTQQ7Nw4cJqX3KX9264OvLIj6ejo+N//3d5hgw5uN6jAQAAANRU1fFq6dKleeqpp3Laaadl/PjxueOOO7qf6+joyD777NP9+aBBg7Jy5cpqX3KX9264uvfeBzNo0KDce++D3QELAAAAYGey1dsGx40bl46Oji0+t2jRomzcuDErVqzIbbfdlrVr1+Zzn/tc/vzP/zxHHXVUzYbce+9+NTvXzuJHP5qf1tb+SZLW1v750Y/mp62trfsx6Ck7QzXsD9WwP1TD/lAN+9O7lPb9Mk/vUtrXxzwfzFbj1bx58973+ba2towaNSqNjY3Ze++981d/9Vd5+umnc9RRR6WtrS3Lly/PgAEDkiQrVqzI0KFDt3nINWt+n66uyjb/up3ZmDFjc++9D6a1tX9WrVqXMWPGJklWrVpX58noTd7dH/gg7A/VsD9Uw/5QDfvT+5T0/Spxf0qbpzQlfX3sz3trbGx43wuXqr5tcNSoUXn00UeTJBs2bMi///u/Z/DgwUmSkSNH5vbbb0+SLFu2LM8880yGDRtW7Uvu8tra9smSJT/Ppz99QlasWJFPf/qELFny87S17bP1XwwAAADQi1T9tw2effbZueyyy/KZz3wmSfLZz342Rx99dJLknHPOyeTJk3PiiSemsbEx06ZN6/7B7nxwTz75fIYMOfh/g1VbEn/bIAAAALBzqjpefehDH8o//MM/bPG5vn375oYbbqj2JdiCd0NViZcdAgAAANRK1bcNAgAAAMD2Il4BAAAAUCzxCgAAAIBiiVcAAAAAFEu8AgAAAKBY4hUAAAAAxRKvAAAAACiWeNVLnXLK2AwcuEcaGhoycOAeOeWUsfUeCQAAAKDmxKte6JRTxuanP30oEye253e/+10mTmzPT3/6kIAFAAAA7HSa6z0A2+6RRx7O2Wefk2uuuS577NE/11xzXZJkzpxZdZ4MAAAAoLbEq16oUqlk6tSvbfLY1Klfy+zZt9RnIAAAgO2kvf30eo9QrJaWlnqPULTx48dn0aKH6j1GscaPH1/vEXpMvOqFGhoactVVX+u+4ipJrrrqa2loaKjjVAAAALU1a9Zt9R5hE+3tpxc3E+/trrvuKur71draP6tWrav3GN3a20/PqFEn13uMHhGveqHjjhvefZXV9dd/M1/5ypcze/YtOf74EXWeDAAAAKC2/MD2XuiOO+bn+ONHZM6cWdlzzz0zZ86sHH/8iNxxx/x6jwYAAABQU6686qXeDVWlXXYIAAAAUEuuvAIAAACgWOIVAAAAAMUSrwAAAAAolngFAAAAQLHEKwAAAACKJV4BAAAAUCzxCgAAAIBiiVcAAAAAFEu8AgAAAKBY4hUAAAAAxRKvAAAAACiWeAUAAABAscQrAAAAAIolXgEAAABQLPEKAAAAgGKJVwAAAAAUS7wCAAAAoFjiFQAAAADFEq8AAAAAKJZ4BQAAAECxxCsAAAAAiiVeAQAAAFAs8QoAAACAYolXAAAAABRLvAIAAACgWOIVAAAAAMUSrwAAAAAolngFAAAAQLHEKwAAAACKJV4BAAAAUCzxCgAAAIBiiVcAAAAAFEu8AgAAAKBY4hUAAAAAxRKvAAAAACiWeAUAAABAscQrAAAAAIolXgEAAABQLPEKAAAAgGKJVwAAAAAUq7neAwAAAABsD+3tp9d7hGK1tLTUe4QeE68AAACAnc6sWbfVe4RNtLefXtxMvYXbBgEAAAAolngFAAAAQLHEKwAAAACKJV4BAAAAUCzxCgAAAIBiiVcAAAAAFEu8AgAAAKBY4hUAAAAAxRKvAAAAACiWeAUAAABAscSrXmrKlEuz776taWhoyL77tmbKlEvrPRIAAABAzYlXvdCUKZdm9uxZmTr1iqxfvz5Tp16R2bNnCVgAAADATke86oVuvXVOLr98Wi644KL07ds3F1xwUS6/fFpuvXVOvUcDAAAAqCnxqhfq7HwrEye2b/LYxInt6ex8q04TAQAAAGwf4lUv1KfP7pkzZ9Ymj82ZMyt9+uxep4kAAAAAtg/xqhc666yJmTbt8tx007eyYcOG3HTTtzJt2uU566yJ9R4NAAAAoKaa6z0A22769GuTJFdd9fVcccVX06fPonRkSgAAEzZJREFU7jn77PbuxwEAAAB2FuJVLzV9+rWZPv3atLb2z6pV6+o9DgAAAMB24bZBAAAAAIolXgEAAABQLPEKAAAAgGKJVwAAAAAUS7wCAAAAoFjiFQAAAADFEq8AAAAAKJZ4BQAAAECxxCsAAAAAiiVeAQAAAFAs8QoAAACAYolXAAAAABRLvAIAAACgWOIVAAAAAMUSrwAAAAAolngFAAAAQLHEKwAAAACKJV4BAAAAUCzxCgAAAIBiiVcAAAAAFEu8AgAAAKBY4hUAAAAAxRKvAAAAACiWeAUAAABAscQrAAAAAIolXgEAAABQLPEKAAAAgGKJVwAAAAAUS7wCAAAAoFjiFQAAAADFEq8AAAAAKJZ4BQAAAECxxCsAAAAAiiVeAQAAAFAs8QoAAACAYolXAAAAABRLvAIAAACgWOIVAAAAAMUSrwAAAAAolngFAAAAQLHEKwAAAACKJV4BAAAAUCzxCgAAAIBiiVcAAAAAFEu8AgAAAKBY4hUAAAAAxRKvAAAAACiWeAUAAABAscQrAAAAAIolXgEAAABQLPEKAAAAgGKJVwAAAAAUS7wCAAAAoFjiFQAAAADFEq8AAAAAKJZ4BQAAAECxxCsAAAAAiiVeAQAAAFAs8QoAAACAYolXAAAAABRLvAIAAACgWOIVAAAAAMUSrwAAAAAolngFAAAAQLHEKwAAAACKJV4BAAAAUCzxCgAAAIBiNVd7grPPPjtr165NkmzcuDEvvPBC7r777gwePDhvvPFGpkyZkmeffTZNTU2ZNGlShg8fXvXQAAAAAOwaqo5Xs2fP7v74wQcfzPXXX5/BgwcnSW655Za0tLTkgQceyLJly3LGGWdkwYIFaWlpqfZlAQAAANgF1PS2wTvvvDMTJkzo/vy+++7LaaedliTZf//9c+ihh2bhwoW1fEkAAAAAdmJVX3n1rtWrV+eJJ57I3//933c/1tHRkX322af780GDBmXlypXbfO699+5Xkxl3Vq2t/es9Ar2Y/aEa9odq2B+qYX+ohv2hGvaHatifD2ar8WrcuHHp6OjY4nOLFi1KU1NTkmTevHkZNmxYBgwYUNsJk6xZ8/t0dVVqft6dQWtr/6xata7eY9BL2R+qYX+ohv2hGvaHatgfqmV/qIb92bLGxob3vXBpq/Fq3rx5PXqhu+66K1/5ylc2eaytrS3Lly/vDlorVqzI0KFDe3Q+AAAAAKjJz7z6j//4j6xbty7HHnvsJo+PHDkyt99+e5Jk2bJleeaZZzJs2LBavCQAAAAAu4CaxKu77rorY8eO7b6F8F3nnHNOXn/99Zx44ok5//zzM23atPTr5+dXAQAAANAzNfmB7VdeeeUWH+/bt29uuOGGWrwEAAAAALugmlx5BQAAAADbg3gFAAAAQLHEKwAAAACKJV4BAAAAUCzxCgAAAIBiiVcAAAAAFEu8AgAAAKBY4hUAAAAAxRKvAAAAACiWeAUAAABAscQrAAAAAIolXgEAAABQLPEKAAAAgGKJVwAAAAAUS7wCAAAAoFjiFQAAAADFEq8AAAAAKJZ4BQAAAECxxCsAAAAAiiVeAQAAAFAs8QoAAACAYolXAAAAABRLvAIAAACgWOIVAAAAAMVqrvcAAAAAsD1NmDA6S5e+UJNzDRkyuOpzHHDAgZk798c1mAZ2DeIVAAAAO7VahaLW1v5ZtWpdTc4F9JzbBgEAAAAolngFAAAAQLHEKwAAAACKJV4BAAAAUCzxCgAAAIBiiVcAAAAAFEu8AgAAAKBY4hUAAAAAxRKvAAAAACiWeAUAAABAscQrAAAAAIolXgEAAABQLPEKAAAAgGKJVwAAAAAUS7wCAAAAoFjiFQAAAADFEq8AAAAAKJZ4BQAAAECxxCsAAAAAiiVeAQAAAFAs8QoAAACAYolXAAAAABRLvAIAAACgWOIVAAAAAMUSrwAAAAAolngFAAAAQLHEKwAAAACKJV4BAAAAUKzmeg8AAAAAUKoJE0Zn6dIXanKuIUMGV32OAw44MHPn/rgG0/Qe4hUAAADAe6hVKGpt7Z9Vq9bV5Fy7GrcNAgAAAFAs8QoAAACAYolXAAAAABRLvAIAAACgWOIVAAAAAMUSrwAAAAAolngFAAAAQLHEKwAAAACKJV4BAAAAUCzxCgAAAIBiiVcAAAAAFEu8AgAAAKBY4hUAAAAAxRKvAAAAACiWeAUAAABAscQrAAAAAIolXgEAAABQLPEKAAAAgGKJVwAAAAAUS7wCAAAAoFjiFQAAAADFEq8AAAAAKJZ4BQAAAECxxCsAAAAAiiVeAQAAAFAs8QoAAACAYolXAAAAABRLvAIAAACgWOIVAAAAAMUSrwAAAAAolngFAAAAQLHEKwAAAACKJV4BAAAAUCzxCgAAAIBiNdd7gJ5obGyo9whF8/WhGvaHatgfqmF/qIb9oRr2h2rYH6phf7Zsa1+XhkqlUtlBswAAAADANnHbIAAAAADFEq8AAAAAKJZ4BQAAAECxxCsAAAAAiiVeAQAAAFAs8QoAAACAYolXAAAAABRLvAIAAACgWOIVAAAAAMUSr3qBl156KaeeempOOumknHrqqVm2bNlmx2zcuDFf//rXc8IJJ+TEE0/MD3/4wx0/KEXqyf7ceOON+cxnPpMxY8Zk/PjxefTRR3f8oBSpJ/vzrhdffDF/8Rd/kRkzZuy4ASlaT/fn3nvvzejRozNq1KiMHj06q1ev3rGDUqSe7M+aNWty3nnnZfTo0Rk5cmS+9rWv5Z133tnxw1KUGTNmZMSIETnooIPy3//931s8xntn3svatWtz7rnn5qSTTsro0aNz0UUX5bXXXtvsODvEe7nwwgszZsyYjB07Nqeffnqef/75zY6xPx9AheKdddZZlfnz51cqlUpl/vz5lbPOOmuzY+bNm1dpb2+vbNy4sbJmzZrKsGHDKi+//PKOHpUC9WR/Fi5cWNmwYUOlUqlUnn/++coRRxxReeONN3bonJSpJ/tTqVQq77zzTuXMM8+s/M3f/E3l6quv3pEjUrCe7M/TTz9d+dSnPlV59dVXK5VKpfL6669X3nzzzR06J2Xqyf5ceeWV3b/ndHZ2Vk4++eTKT37ykx06J+X5xS9+Ueno6KgMHz688qtf/WqLx3jvzHtZu3Zt5Wc/+1n351dffXVlypQpmx1nh3gvr7/+evfHDzzwQGXs2LGbHWN/tp0rrwq3Zs2aPPfccxk1alSSZNSoUXnuuec2q//33ntv/vqv/zqNjY0ZMGBATjjhhNx///31GJmC9HR/hg0blg9/+MNJkoMOOiiVSiW/+93vdvi8lKWn+5Mk3/nOd3L88cdn//3338FTUqqe7s/s2bPT3t6e1tbWJEn//v2z++677/B5KUtP96ehoSHr169PV1dXOjs78/bbb2fgwIH1GJmCHHnkkRk0aND7HuO9M+9lzz33zNChQ7s/HzJkSDo6OjY7zg7xXvr379/98e9///s0NDRsdoz92XbiVeFWrFiRgQMHpqmpKUnS1NSUP/mTP8mKFSs2O66tra3780GDBmXlypU7dFbK09P9+b/mz5+f/fbbL3/6p3+6o8akUD3dn//6r//KY489lrPPPrsOU1Kqnu7P0qVL8/LLL+eMM87IuHHj8u1vfzuVSqUeI1OQnu7PhRdemJdeeinHHHNM9z9HHHFEPUaml/HemZ7o6urK97///YwYMWKz5+wQ72fq1Kk5/vjjc911123xR2rYn20nXgHdfv7zn+cf//Ef881vfrPeo9BLvP3227nsssvy9a9/vfs/MmFbbNy4Mb/61a/y3e9+N7feemsWLlyYu+++u95j0Uvcf//9Oeigg/LYY49l4cKFWbJkiT+5BmrmG9/4Rvr27Zszzzyz3qPQy1x11VX56U9/mksuuSTXXHNNvcfZKYhXhRs0aFBeeeWVbNy4Mckf3uS/+uqrm10KPWjQoE0uZ12xYoUrZ+jx/iTJL3/5y/zt3/5tbrzxxnz0ox/d0aNSoJ7sz6pVq/Lb3/425513XkaMGJE5c+bkjjvuyGWXXVavsSlET3//aWtry8iRI9OnT5/069cvn/zkJ/P000/XY2QK0tP9+Zd/+ZeMGTMmjY2N6d+/f0aMGJHFixfXY2R6Ge+d2ZoZM2bkN7/5Ta6//vo0Nm7+n812iJ4YO3ZsFi9enLVr127yuP3ZduJV4fbee+8cfPDBueeee5Ik99xzTw4++OAMGDBgk+NGjhyZH/7wh+nq6sprr72WBx98MCeddFI9RqYgPd2fp59+OpdcckluuOGGHHLIIfUYlQL1ZH/a2tqyePHiPPTQQ3nooYcyceLEnHLKKfnGN75Rr7EpRE9//xk1alQee+yxVCqVvP322/nZz36WwYMH12NkCtLT/dl3332zcOHCJElnZ2eeeOKJHHjggTt8Xnof7515P9ddd13+8z//MzfeeGP69OmzxWPsEFuyfv36TW5xf+ihh7LHHntkzz333OQ4+7PtGip+sETxli5dmsmTJ+f111/PH/3RH2XGjBn56Ec/mnPPPTcXX3xxDjvssGzcuDHTpk3L448/niQ599xzc+qpp9Z5ckrQk/2ZMGFCli9fvskPub3mmmty0EEH1XFyStCT/fm/Zs6cmQ0bNmTSpEl1mpiS9GR/urq6MmPGjCxcuDCNjY055phjMmnSpC3+KTe7lp7sz29/+9tcccUVWb16dTZu3JihQ4dm6tSpaW5urvf41NGVV16ZBQsWZPXq1dlrr72y55575ic/+Yn3zvTICy+8kFGjRmX//ffPhz70oSR/COU33nijHWKrVq9enQsvvDBvvPFGGhsbs8cee2TSpEk55JBD7E+VxCsAAAAAiuWPNQEAAAAolngFAAAAQLHEKwAAAACKJV4BAAAAUCzxCgAAAIBiiVcAAFWaPHlyrrvuuixZsiQnnXRSvccBANipiFcAADVy5JFH5l//9V+3etzMmTNz6aWX7oCJAAB6P/EKAAAAgGKJVwAA2+i5557LuHHjcvjhh+dLX/pS3nrrrSTJ4sWLc+yxx3Yf953vfCfDhg3L4YcfnpNOOilPPPFEFi5cmJtvvjn33XdfDj/88IwZMyZJMnfu3HzqU5/K4Ycfnk9+8pP5wQ9+0H2ed887a9asfOITn8gxxxyTuXPndj//5ptv5uqrr87w4cNzxBFH5HOf+1zefPPNJMmTTz6Z0047LUceeWTGjBmTxYsX74gvEQBAzTTXewAAgN6ks7MzX/jCFzJx4sScccYZ+bd/+7d8+ctfzuc///lNjnvxxRfzve99L3feeWcGDhyY//mf/0lXV1f222+/nH/++fnNb36Ta6+9tvv4vffeOzfffHM+8pGP5Be/+EXOPffcHHbYYTnkkEOSJKtXr866deuycOHCLFq0KBdffHFOOOGE7LHHHpkxY0Z+/etf5wc/+EH++I//OE899VQaGxvzyiuv5Pzzz88111yTYcOG5YknnsjFF1+c++67LwMGDNihXzcAgA/KlVcAANvgqaeeyttvv52JEydmt912y8iRI3PYYYdtdlxTU1M6OzuzdOnSvP3229l3332z3377ved5jz/++Oy3335paGjIxz/+8Rx99NFZsmRJ9/PNzc35whe+kN122y3HHXdc+vbtm5deeildXV2ZO3dupk6dmoEDB6apqSl/+Zd/mT59+uTuu+/Osccem+OOOy6NjY05+uijc+ihh+aRRx7ZLl8bAIDtwZVXAADb4NVXX83AgQPT0NDQ/VhbW9tmx/3Zn/1ZvvrVr2bmzJn59a9/nWOOOSaTJ0/OwIEDt3jeRx55JDfeeGOWLVuWrq6uvPnmm/nYxz7W/fyee+6Z5ub//9btwx/+cDZs2JC1a9fmrbfeykc+8pHNztnR0ZH7778/Dz/8cPdj77zzToYOHfqB/t0BAOrBlVcAANugtbU1r7zySiqVSvdjHR0dWzx29OjR+f73v5+HH344DQ0N3bcJ/t/wlfzhVsSLL7447e3tefzxx7NkyZIce+yxm7zGe9lrr72y++675+WXX97suUGDBuWzn/1slixZ0v3Pk08+mfPOO29b/pUBAOpKvAIA2AZDhgxJc3Nz/vmf/znvvPNOFixYkGeeeWaz41588cU88cQT6ezsTJ8+fbL77runqakpyR9+vtXy5cvT1dWV5A/xqrOzMwMGDEhzc3MeeeSRPP744z2ap7GxMRMmTMj06dPzyiuvZOPGjfnlL3+Zzs7OjBkzJg8//HAeffTRbNy4MW+99VYWL16clStX1u4LAgCwnYlXAADboE+fPpk5c2bmzZuXo446Kvfee29OPPHEzY7r7OzMN7/5zQwdOjTHHHNMXnvttVxyySVJkpEjRyZJhg4dmnHjxqVfv375u7/7u3zpS1/KUUcdlXvuuScjRozo8UyTJk3Kxz72sZx88sn5+Mc/nmuvvTZdXV0ZNGhQvv3tb+fmm2/OJz7xiRx33HG55ZZbuqMZAEBv0FDpyfXoAAAAAFAHrrwCAAAAoFjiFQAAAADFEq8AAAAAKJZ4BQAAAECxxCsAAAAAiiVeAQAAAFAs8QoAAACAYolXAAAAABRLvAIAAACgWP8Pr5uZoP/KMcYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1440x1080 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Mixing data from all anchors\n",
    "fig, ax = plt.subplots(figsize=(20,15))\n",
    "\n",
    "data.boxplot(column='RSSI', by='distance', ax=ax)\n",
    "ax.set_title(\"Mixed data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove distance=0 outliers  \n",
    "indexnames = data[(data.distance == 0) & (data.RSSI < -35)].index\n",
    "data.drop(indexnames, inplace=True, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USING GAUSSIAN NAIVE BAYES MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUILDING TRAIN & TEST SETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split in train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(data['RSSI']).reshape(-1,1), np.array(data['dist_<_1m']).reshape(-1,1), test_size=data.shape[0]//3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APPLY GAUSSIAN NAIVE-BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation accuracy f1_macro score:\n",
      " mean=0.8147292563562443\n",
      " std=0.009306037793008879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#apply a gaussian naive-bayes\n",
    "NB_model = GaussianNB()\n",
    "NB_model.fit(X_train, y_train)\n",
    "\n",
    "#using cross validation\n",
    "NB_model_cv = GaussianNB()\n",
    "scores = cross_val_score(NB_model_cv, X_train, y_train, cv=10, scoring='f1_macro')\n",
    "\n",
    "print(f'cross validation accuracy f1_macro score:\\n mean={scores.mean()}\\n std={scores.std()}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USING SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUILDING TRAIN & TEST SETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split in train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(data['RSSI']).reshape(-1,1), np.array(data['dist_<_1m']).reshape(-1,1), test_size=data.shape[0]//3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCALE TRAIN & TEST SETS SEPARATELY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NO HACE FALTA ESCALAR PORQUE SOLO HAY UNA FEATURE\n",
    "#scaler = StandardScaler()\n",
    "#X_train = scaler.fit_transform(X_train)\n",
    "#X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INITIALIZING LISTS OF HYPERPARAMETERS FOR GRIDSEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = ['linear', 'rbf', 'sigmoid']\n",
    "Cs = [0.001, 0.1, 1, 10, 100, 1000]\n",
    "gammas = [0.1, 0.5, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APPLY SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8374688923478356\n",
      "{'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(class_weight='balanced')\n",
    "\n",
    "trc = GridSearchCV(estimator=svc,\n",
    "                   param_grid={\n",
    "                       'C': Cs,\n",
    "                       'kernel': kernels,\n",
    "                       'gamma': gammas\n",
    "                   },\n",
    "                   scoring=['accuracy', 'recall_macro', 'f1_macro'],\n",
    "                   cv=10,\n",
    "                   n_jobs=-1,\n",
    "                   return_train_score=True,\n",
    "                   refit='f1_macro')\n",
    "\n",
    "svc_model_10CV = trc.fit(X_train, y_train)\n",
    "\n",
    "print(svc_model_10CV.best_score_)\n",
    "print(svc_model_10CV.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>mean_test_recall_macro</th>\n",
       "      <th>std_test_recall_macro</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>std_test_f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.588143</td>\n",
       "      <td>0.008817</td>\n",
       "      <td>100</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.837493</td>\n",
       "      <td>0.016483</td>\n",
       "      <td>0.837622</td>\n",
       "      <td>0.016469</td>\n",
       "      <td>0.837469</td>\n",
       "      <td>0.016490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.789716</td>\n",
       "      <td>0.252676</td>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.837493</td>\n",
       "      <td>0.016483</td>\n",
       "      <td>0.837622</td>\n",
       "      <td>0.016469</td>\n",
       "      <td>0.837469</td>\n",
       "      <td>0.016490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.580329</td>\n",
       "      <td>0.015560</td>\n",
       "      <td>1000</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.837493</td>\n",
       "      <td>0.016483</td>\n",
       "      <td>0.837622</td>\n",
       "      <td>0.016469</td>\n",
       "      <td>0.837469</td>\n",
       "      <td>0.016490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.685588</td>\n",
       "      <td>0.093325</td>\n",
       "      <td>1000</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.837493</td>\n",
       "      <td>0.016483</td>\n",
       "      <td>0.837622</td>\n",
       "      <td>0.016469</td>\n",
       "      <td>0.837469</td>\n",
       "      <td>0.016490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.639400</td>\n",
       "      <td>0.020191</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.837493</td>\n",
       "      <td>0.016483</td>\n",
       "      <td>0.837622</td>\n",
       "      <td>0.016469</td>\n",
       "      <td>0.837469</td>\n",
       "      <td>0.016490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.612934</td>\n",
       "      <td>0.007274</td>\n",
       "      <td>100</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.837493</td>\n",
       "      <td>0.016483</td>\n",
       "      <td>0.837622</td>\n",
       "      <td>0.016469</td>\n",
       "      <td>0.837469</td>\n",
       "      <td>0.016490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.710615</td>\n",
       "      <td>0.054130</td>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.837493</td>\n",
       "      <td>0.016483</td>\n",
       "      <td>0.837622</td>\n",
       "      <td>0.016469</td>\n",
       "      <td>0.837469</td>\n",
       "      <td>0.016490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.915052</td>\n",
       "      <td>0.192550</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.836994</td>\n",
       "      <td>0.015088</td>\n",
       "      <td>0.836943</td>\n",
       "      <td>0.015082</td>\n",
       "      <td>0.836950</td>\n",
       "      <td>0.015101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.799490</td>\n",
       "      <td>0.052628</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.836162</td>\n",
       "      <td>0.015397</td>\n",
       "      <td>0.836285</td>\n",
       "      <td>0.015348</td>\n",
       "      <td>0.836142</td>\n",
       "      <td>0.015408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>7.498327</td>\n",
       "      <td>3.750494</td>\n",
       "      <td>1000</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.835663</td>\n",
       "      <td>0.013805</td>\n",
       "      <td>0.835573</td>\n",
       "      <td>0.013773</td>\n",
       "      <td>0.835573</td>\n",
       "      <td>0.013790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.667691</td>\n",
       "      <td>0.018070</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.835495</td>\n",
       "      <td>0.014771</td>\n",
       "      <td>0.835648</td>\n",
       "      <td>0.014755</td>\n",
       "      <td>0.835469</td>\n",
       "      <td>0.014775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3.807356</td>\n",
       "      <td>0.379353</td>\n",
       "      <td>100</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.833998</td>\n",
       "      <td>0.014489</td>\n",
       "      <td>0.833889</td>\n",
       "      <td>0.014452</td>\n",
       "      <td>0.833924</td>\n",
       "      <td>0.014477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.763939</td>\n",
       "      <td>0.031458</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.822843</td>\n",
       "      <td>0.013538</td>\n",
       "      <td>0.823372</td>\n",
       "      <td>0.013479</td>\n",
       "      <td>0.822318</td>\n",
       "      <td>0.013661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.830958</td>\n",
       "      <td>0.088619</td>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.820680</td>\n",
       "      <td>0.010026</td>\n",
       "      <td>0.821180</td>\n",
       "      <td>0.009953</td>\n",
       "      <td>0.820177</td>\n",
       "      <td>0.010183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.934716</td>\n",
       "      <td>0.118676</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.809359</td>\n",
       "      <td>0.011349</td>\n",
       "      <td>0.810463</td>\n",
       "      <td>0.011263</td>\n",
       "      <td>0.806331</td>\n",
       "      <td>0.012111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3.135069</td>\n",
       "      <td>0.607568</td>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.798540</td>\n",
       "      <td>0.018633</td>\n",
       "      <td>0.798722</td>\n",
       "      <td>0.018601</td>\n",
       "      <td>0.798476</td>\n",
       "      <td>0.018662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3.278359</td>\n",
       "      <td>0.638786</td>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>0.798540</td>\n",
       "      <td>0.018633</td>\n",
       "      <td>0.798722</td>\n",
       "      <td>0.018601</td>\n",
       "      <td>0.798476</td>\n",
       "      <td>0.018662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.396611</td>\n",
       "      <td>0.017328</td>\n",
       "      <td>0.001</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.798540</td>\n",
       "      <td>0.018633</td>\n",
       "      <td>0.798722</td>\n",
       "      <td>0.018601</td>\n",
       "      <td>0.798476</td>\n",
       "      <td>0.018662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>25.837142</td>\n",
       "      <td>6.765484</td>\n",
       "      <td>100</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.798540</td>\n",
       "      <td>0.018633</td>\n",
       "      <td>0.798722</td>\n",
       "      <td>0.018601</td>\n",
       "      <td>0.798476</td>\n",
       "      <td>0.018662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>24.199744</td>\n",
       "      <td>6.141476</td>\n",
       "      <td>100</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>0.798540</td>\n",
       "      <td>0.018633</td>\n",
       "      <td>0.798722</td>\n",
       "      <td>0.018601</td>\n",
       "      <td>0.798476</td>\n",
       "      <td>0.018662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>191.663135</td>\n",
       "      <td>24.512101</td>\n",
       "      <td>1000</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.798540</td>\n",
       "      <td>0.018633</td>\n",
       "      <td>0.798722</td>\n",
       "      <td>0.018601</td>\n",
       "      <td>0.798476</td>\n",
       "      <td>0.018662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>208.229615</td>\n",
       "      <td>23.672017</td>\n",
       "      <td>1000</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.798540</td>\n",
       "      <td>0.018633</td>\n",
       "      <td>0.798722</td>\n",
       "      <td>0.018601</td>\n",
       "      <td>0.798476</td>\n",
       "      <td>0.018662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>202.331800</td>\n",
       "      <td>41.530742</td>\n",
       "      <td>1000</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>0.798540</td>\n",
       "      <td>0.018633</td>\n",
       "      <td>0.798722</td>\n",
       "      <td>0.018601</td>\n",
       "      <td>0.798476</td>\n",
       "      <td>0.018662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>25.034485</td>\n",
       "      <td>6.382510</td>\n",
       "      <td>100</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.798540</td>\n",
       "      <td>0.018633</td>\n",
       "      <td>0.798722</td>\n",
       "      <td>0.018601</td>\n",
       "      <td>0.798476</td>\n",
       "      <td>0.018662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.111593</td>\n",
       "      <td>0.643213</td>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.798540</td>\n",
       "      <td>0.018633</td>\n",
       "      <td>0.798722</td>\n",
       "      <td>0.018601</td>\n",
       "      <td>0.798476</td>\n",
       "      <td>0.018662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.996170</td>\n",
       "      <td>0.150359</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>0.798540</td>\n",
       "      <td>0.018633</td>\n",
       "      <td>0.798722</td>\n",
       "      <td>0.018601</td>\n",
       "      <td>0.798476</td>\n",
       "      <td>0.018662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.221646</td>\n",
       "      <td>0.318057</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.798540</td>\n",
       "      <td>0.018633</td>\n",
       "      <td>0.798722</td>\n",
       "      <td>0.018601</td>\n",
       "      <td>0.798476</td>\n",
       "      <td>0.018662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.388232</td>\n",
       "      <td>0.043166</td>\n",
       "      <td>0.001</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.798540</td>\n",
       "      <td>0.018633</td>\n",
       "      <td>0.798722</td>\n",
       "      <td>0.018601</td>\n",
       "      <td>0.798476</td>\n",
       "      <td>0.018662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.476682</td>\n",
       "      <td>0.074473</td>\n",
       "      <td>0.001</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>0.798540</td>\n",
       "      <td>0.018633</td>\n",
       "      <td>0.798722</td>\n",
       "      <td>0.018601</td>\n",
       "      <td>0.798476</td>\n",
       "      <td>0.018662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.543315</td>\n",
       "      <td>0.029577</td>\n",
       "      <td>0.1</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.798540</td>\n",
       "      <td>0.018633</td>\n",
       "      <td>0.798722</td>\n",
       "      <td>0.018601</td>\n",
       "      <td>0.798476</td>\n",
       "      <td>0.018662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.714878</td>\n",
       "      <td>0.145216</td>\n",
       "      <td>0.1</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>0.798540</td>\n",
       "      <td>0.018633</td>\n",
       "      <td>0.798722</td>\n",
       "      <td>0.018601</td>\n",
       "      <td>0.798476</td>\n",
       "      <td>0.018662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.673382</td>\n",
       "      <td>0.141937</td>\n",
       "      <td>0.1</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.798540</td>\n",
       "      <td>0.018633</td>\n",
       "      <td>0.798722</td>\n",
       "      <td>0.018601</td>\n",
       "      <td>0.798476</td>\n",
       "      <td>0.018662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.933818</td>\n",
       "      <td>0.153530</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.798540</td>\n",
       "      <td>0.018633</td>\n",
       "      <td>0.798722</td>\n",
       "      <td>0.018601</td>\n",
       "      <td>0.798476</td>\n",
       "      <td>0.018662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.746622</td>\n",
       "      <td>0.034995</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.762248</td>\n",
       "      <td>0.018926</td>\n",
       "      <td>0.762531</td>\n",
       "      <td>0.017804</td>\n",
       "      <td>0.752502</td>\n",
       "      <td>0.020287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.016216</td>\n",
       "      <td>0.085944</td>\n",
       "      <td>100</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.504496</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.335325</td>\n",
       "      <td>0.000182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.925037</td>\n",
       "      <td>0.017310</td>\n",
       "      <td>100</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.504496</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.335325</td>\n",
       "      <td>0.000182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.919134</td>\n",
       "      <td>0.012064</td>\n",
       "      <td>100</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1</td>\n",
       "      <td>0.504496</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.335325</td>\n",
       "      <td>0.000182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.036255</td>\n",
       "      <td>0.057636</td>\n",
       "      <td>10</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.499504</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333107</td>\n",
       "      <td>0.001993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.418141</td>\n",
       "      <td>0.230074</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.499504</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333107</td>\n",
       "      <td>0.001993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.893480</td>\n",
       "      <td>0.090322</td>\n",
       "      <td>0.001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.499504</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333107</td>\n",
       "      <td>0.001993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.931824</td>\n",
       "      <td>0.062527</td>\n",
       "      <td>1000</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.499504</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333107</td>\n",
       "      <td>0.001993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.912081</td>\n",
       "      <td>0.128120</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.499504</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333107</td>\n",
       "      <td>0.001993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.033465</td>\n",
       "      <td>0.195570</td>\n",
       "      <td>0.001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.499504</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333107</td>\n",
       "      <td>0.001993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.891309</td>\n",
       "      <td>0.007715</td>\n",
       "      <td>1000</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.499504</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333107</td>\n",
       "      <td>0.001993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.014250</td>\n",
       "      <td>0.055826</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.499504</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333107</td>\n",
       "      <td>0.001993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.010108</td>\n",
       "      <td>0.050820</td>\n",
       "      <td>0.001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1</td>\n",
       "      <td>0.499504</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333107</td>\n",
       "      <td>0.001993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.978829</td>\n",
       "      <td>0.018197</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.499504</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333107</td>\n",
       "      <td>0.001993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.011097</td>\n",
       "      <td>0.067257</td>\n",
       "      <td>10</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.499504</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333107</td>\n",
       "      <td>0.001993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.087276</td>\n",
       "      <td>0.138153</td>\n",
       "      <td>0.1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.499504</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333107</td>\n",
       "      <td>0.001993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.031301</td>\n",
       "      <td>0.074423</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1</td>\n",
       "      <td>0.499504</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333107</td>\n",
       "      <td>0.001993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.052977</td>\n",
       "      <td>0.188805</td>\n",
       "      <td>0.1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.499504</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333107</td>\n",
       "      <td>0.001993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.017154</td>\n",
       "      <td>0.068477</td>\n",
       "      <td>10</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1</td>\n",
       "      <td>0.499504</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333107</td>\n",
       "      <td>0.001993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.266245</td>\n",
       "      <td>0.260940</td>\n",
       "      <td>0.1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1</td>\n",
       "      <td>0.499504</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333107</td>\n",
       "      <td>0.001993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.918012</td>\n",
       "      <td>0.025180</td>\n",
       "      <td>1000</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1</td>\n",
       "      <td>0.499504</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333107</td>\n",
       "      <td>0.001993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time param_C param_kernel param_gamma  \\\n",
       "43       0.588143      0.008817     100          rbf           1   \n",
       "34       0.789716      0.252676      10          rbf           1   \n",
       "52       0.580329      0.015560    1000          rbf           1   \n",
       "49       0.685588      0.093325    1000          rbf         0.5   \n",
       "25       0.639400      0.020191       1          rbf           1   \n",
       "40       0.612934      0.007274     100          rbf         0.5   \n",
       "31       0.710615      0.054130      10          rbf         0.5   \n",
       "13       0.915052      0.192550     0.1          rbf         0.5   \n",
       "16       0.799490      0.052628     0.1          rbf           1   \n",
       "46       7.498327      3.750494    1000          rbf         0.1   \n",
       "22       0.667691      0.018070       1          rbf         0.5   \n",
       "37       3.807356      0.379353     100          rbf         0.1   \n",
       "19       0.763939      0.031458       1          rbf         0.1   \n",
       "28       0.830958      0.088619      10          rbf         0.1   \n",
       "10       0.934716      0.118676     0.1          rbf         0.1   \n",
       "30       3.135069      0.607568      10       linear         0.5   \n",
       "33       3.278359      0.638786      10       linear           1   \n",
       "0        0.396611      0.017328   0.001       linear         0.1   \n",
       "36      25.837142      6.765484     100       linear         0.1   \n",
       "42      24.199744      6.141476     100       linear           1   \n",
       "45     191.663135     24.512101    1000       linear         0.1   \n",
       "48     208.229615     23.672017    1000       linear         0.5   \n",
       "51     202.331800     41.530742    1000       linear           1   \n",
       "39      25.034485      6.382510     100       linear         0.5   \n",
       "27       3.111593      0.643213      10       linear         0.1   \n",
       "24       0.996170      0.150359       1       linear           1   \n",
       "18       1.221646      0.318057       1       linear         0.1   \n",
       "3        0.388232      0.043166   0.001       linear         0.5   \n",
       "6        0.476682      0.074473   0.001       linear           1   \n",
       "9        0.543315      0.029577     0.1       linear         0.1   \n",
       "15       0.714878      0.145216     0.1       linear           1   \n",
       "12       0.673382      0.141937     0.1       linear         0.5   \n",
       "21       0.933818      0.153530       1       linear         0.5   \n",
       "1        1.746622      0.034995   0.001          rbf         0.1   \n",
       "38       1.016216      0.085944     100      sigmoid         0.1   \n",
       "41       0.925037      0.017310     100      sigmoid         0.5   \n",
       "44       0.919134      0.012064     100      sigmoid           1   \n",
       "32       1.036255      0.057636      10      sigmoid         0.5   \n",
       "7        2.418141      0.230074   0.001          rbf           1   \n",
       "2        0.893480      0.090322   0.001      sigmoid         0.1   \n",
       "50       0.931824      0.062527    1000      sigmoid         0.5   \n",
       "4        1.912081      0.128120   0.001          rbf         0.5   \n",
       "5        1.033465      0.195570   0.001      sigmoid         0.5   \n",
       "47       0.891309      0.007715    1000      sigmoid         0.1   \n",
       "23       1.014250      0.055826       1      sigmoid         0.5   \n",
       "8        1.010108      0.050820   0.001      sigmoid           1   \n",
       "20       0.978829      0.018197       1      sigmoid         0.1   \n",
       "29       1.011097      0.067257      10      sigmoid         0.1   \n",
       "11       1.087276      0.138153     0.1      sigmoid         0.1   \n",
       "26       1.031301      0.074423       1      sigmoid           1   \n",
       "14       1.052977      0.188805     0.1      sigmoid         0.5   \n",
       "35       1.017154      0.068477      10      sigmoid           1   \n",
       "17       1.266245      0.260940     0.1      sigmoid           1   \n",
       "53       0.918012      0.025180    1000      sigmoid           1   \n",
       "\n",
       "    mean_test_accuracy  std_test_accuracy  mean_test_recall_macro  \\\n",
       "43            0.837493           0.016483                0.837622   \n",
       "34            0.837493           0.016483                0.837622   \n",
       "52            0.837493           0.016483                0.837622   \n",
       "49            0.837493           0.016483                0.837622   \n",
       "25            0.837493           0.016483                0.837622   \n",
       "40            0.837493           0.016483                0.837622   \n",
       "31            0.837493           0.016483                0.837622   \n",
       "13            0.836994           0.015088                0.836943   \n",
       "16            0.836162           0.015397                0.836285   \n",
       "46            0.835663           0.013805                0.835573   \n",
       "22            0.835495           0.014771                0.835648   \n",
       "37            0.833998           0.014489                0.833889   \n",
       "19            0.822843           0.013538                0.823372   \n",
       "28            0.820680           0.010026                0.821180   \n",
       "10            0.809359           0.011349                0.810463   \n",
       "30            0.798540           0.018633                0.798722   \n",
       "33            0.798540           0.018633                0.798722   \n",
       "0             0.798540           0.018633                0.798722   \n",
       "36            0.798540           0.018633                0.798722   \n",
       "42            0.798540           0.018633                0.798722   \n",
       "45            0.798540           0.018633                0.798722   \n",
       "48            0.798540           0.018633                0.798722   \n",
       "51            0.798540           0.018633                0.798722   \n",
       "39            0.798540           0.018633                0.798722   \n",
       "27            0.798540           0.018633                0.798722   \n",
       "24            0.798540           0.018633                0.798722   \n",
       "18            0.798540           0.018633                0.798722   \n",
       "3             0.798540           0.018633                0.798722   \n",
       "6             0.798540           0.018633                0.798722   \n",
       "9             0.798540           0.018633                0.798722   \n",
       "15            0.798540           0.018633                0.798722   \n",
       "12            0.798540           0.018633                0.798722   \n",
       "21            0.798540           0.018633                0.798722   \n",
       "1             0.762248           0.018926                0.762531   \n",
       "38            0.504496           0.000412                0.500000   \n",
       "41            0.504496           0.000412                0.500000   \n",
       "44            0.504496           0.000412                0.500000   \n",
       "32            0.499504           0.004487                0.500000   \n",
       "7             0.499504           0.004487                0.500000   \n",
       "2             0.499504           0.004487                0.500000   \n",
       "50            0.499504           0.004487                0.500000   \n",
       "4             0.499504           0.004487                0.500000   \n",
       "5             0.499504           0.004487                0.500000   \n",
       "47            0.499504           0.004487                0.500000   \n",
       "23            0.499504           0.004487                0.500000   \n",
       "8             0.499504           0.004487                0.500000   \n",
       "20            0.499504           0.004487                0.500000   \n",
       "29            0.499504           0.004487                0.500000   \n",
       "11            0.499504           0.004487                0.500000   \n",
       "26            0.499504           0.004487                0.500000   \n",
       "14            0.499504           0.004487                0.500000   \n",
       "35            0.499504           0.004487                0.500000   \n",
       "17            0.499504           0.004487                0.500000   \n",
       "53            0.499504           0.004487                0.500000   \n",
       "\n",
       "    std_test_recall_macro  mean_test_f1_macro  std_test_f1_macro  \n",
       "43               0.016469            0.837469           0.016490  \n",
       "34               0.016469            0.837469           0.016490  \n",
       "52               0.016469            0.837469           0.016490  \n",
       "49               0.016469            0.837469           0.016490  \n",
       "25               0.016469            0.837469           0.016490  \n",
       "40               0.016469            0.837469           0.016490  \n",
       "31               0.016469            0.837469           0.016490  \n",
       "13               0.015082            0.836950           0.015101  \n",
       "16               0.015348            0.836142           0.015408  \n",
       "46               0.013773            0.835573           0.013790  \n",
       "22               0.014755            0.835469           0.014775  \n",
       "37               0.014452            0.833924           0.014477  \n",
       "19               0.013479            0.822318           0.013661  \n",
       "28               0.009953            0.820177           0.010183  \n",
       "10               0.011263            0.806331           0.012111  \n",
       "30               0.018601            0.798476           0.018662  \n",
       "33               0.018601            0.798476           0.018662  \n",
       "0                0.018601            0.798476           0.018662  \n",
       "36               0.018601            0.798476           0.018662  \n",
       "42               0.018601            0.798476           0.018662  \n",
       "45               0.018601            0.798476           0.018662  \n",
       "48               0.018601            0.798476           0.018662  \n",
       "51               0.018601            0.798476           0.018662  \n",
       "39               0.018601            0.798476           0.018662  \n",
       "27               0.018601            0.798476           0.018662  \n",
       "24               0.018601            0.798476           0.018662  \n",
       "18               0.018601            0.798476           0.018662  \n",
       "3                0.018601            0.798476           0.018662  \n",
       "6                0.018601            0.798476           0.018662  \n",
       "9                0.018601            0.798476           0.018662  \n",
       "15               0.018601            0.798476           0.018662  \n",
       "12               0.018601            0.798476           0.018662  \n",
       "21               0.018601            0.798476           0.018662  \n",
       "1                0.017804            0.752502           0.020287  \n",
       "38               0.000000            0.335325           0.000182  \n",
       "41               0.000000            0.335325           0.000182  \n",
       "44               0.000000            0.335325           0.000182  \n",
       "32               0.000000            0.333107           0.001993  \n",
       "7                0.000000            0.333107           0.001993  \n",
       "2                0.000000            0.333107           0.001993  \n",
       "50               0.000000            0.333107           0.001993  \n",
       "4                0.000000            0.333107           0.001993  \n",
       "5                0.000000            0.333107           0.001993  \n",
       "47               0.000000            0.333107           0.001993  \n",
       "23               0.000000            0.333107           0.001993  \n",
       "8                0.000000            0.333107           0.001993  \n",
       "20               0.000000            0.333107           0.001993  \n",
       "29               0.000000            0.333107           0.001993  \n",
       "11               0.000000            0.333107           0.001993  \n",
       "26               0.000000            0.333107           0.001993  \n",
       "14               0.000000            0.333107           0.001993  \n",
       "35               0.000000            0.333107           0.001993  \n",
       "17               0.000000            0.333107           0.001993  \n",
       "53               0.000000            0.333107           0.001993  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(svc_model_10CV.cv_results_).loc[:, [\n",
    "    'mean_fit_time',\n",
    "    'std_fit_time',\n",
    "    'param_C',\n",
    "    'param_kernel',\n",
    "    'param_gamma',\n",
    "    'mean_test_accuracy',\n",
    "    'std_test_accuracy',\n",
    "    'mean_test_recall_macro',\n",
    "    'std_test_recall_macro',\n",
    "    'mean_test_f1_macro',\n",
    "    'std_test_f1_macro',\n",
    "]].sort_values(by='mean_test_f1_macro',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INITIALIZING LISTS OF HYPERPARAMETERS FOR GRIDSEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = ['poly']\n",
    "degrees = [2,3,4,5]#,3,4,5]\n",
    "Cs = [0.01, 0.1, 1, 10, 100, 1000]\n",
    "gammas = [0.1,0.5,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-40b47409f130>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m                    refit='f1_macro')\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0msvc_model_10CV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvc_model_10CV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Try 'poly' kernel (the best for this case) with different degrees\n",
    "\n",
    "svc = SVC(class_weight='balanced')\n",
    "\n",
    "trc = GridSearchCV(estimator=svc,\n",
    "                   param_grid={\n",
    "                       'kernel': kernels,\n",
    "                       'degree': degrees,\n",
    "                       'C': Cs,\n",
    "                       'gamma': gammas\n",
    "                   },\n",
    "                   scoring=['accuracy', 'recall_macro', 'f1_macro'],\n",
    "                   cv=10,\n",
    "                   n_jobs=-1,\n",
    "                   return_train_score=True,\n",
    "                   refit='f1_macro')\n",
    "\n",
    "svc_model_10CV = trc.fit(X_train, y_train)\n",
    "\n",
    "print(svc_model_10CV.best_score_)\n",
    "print(svc_model_10CV.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>mean_test_recall_macro</th>\n",
       "      <th>std_test_recall_macro</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>std_test_f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.443674</td>\n",
       "      <td>0.009745</td>\n",
       "      <td>10</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.811190</td>\n",
       "      <td>0.012137</td>\n",
       "      <td>0.813526</td>\n",
       "      <td>0.011979</td>\n",
       "      <td>0.807913</td>\n",
       "      <td>0.012640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.441488</td>\n",
       "      <td>0.011680</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>1</td>\n",
       "      <td>0.811190</td>\n",
       "      <td>0.012137</td>\n",
       "      <td>0.813526</td>\n",
       "      <td>0.011979</td>\n",
       "      <td>0.807913</td>\n",
       "      <td>0.012640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.575507</td>\n",
       "      <td>0.006302</td>\n",
       "      <td>0.1</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.811190</td>\n",
       "      <td>0.012137</td>\n",
       "      <td>0.813526</td>\n",
       "      <td>0.011979</td>\n",
       "      <td>0.807913</td>\n",
       "      <td>0.012640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.435308</td>\n",
       "      <td>0.006793</td>\n",
       "      <td>10</td>\n",
       "      <td>poly</td>\n",
       "      <td>1</td>\n",
       "      <td>0.810524</td>\n",
       "      <td>0.012841</td>\n",
       "      <td>0.812918</td>\n",
       "      <td>0.012617</td>\n",
       "      <td>0.807040</td>\n",
       "      <td>0.013557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.597121</td>\n",
       "      <td>0.020703</td>\n",
       "      <td>10</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.807360</td>\n",
       "      <td>0.013377</td>\n",
       "      <td>0.809856</td>\n",
       "      <td>0.013147</td>\n",
       "      <td>0.803429</td>\n",
       "      <td>0.014293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.489205</td>\n",
       "      <td>0.013535</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.806528</td>\n",
       "      <td>0.013807</td>\n",
       "      <td>0.808921</td>\n",
       "      <td>0.013663</td>\n",
       "      <td>0.802867</td>\n",
       "      <td>0.014519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.497620</td>\n",
       "      <td>0.015380</td>\n",
       "      <td>0.1</td>\n",
       "      <td>poly</td>\n",
       "      <td>1</td>\n",
       "      <td>0.805528</td>\n",
       "      <td>0.011005</td>\n",
       "      <td>0.808073</td>\n",
       "      <td>0.010842</td>\n",
       "      <td>0.801417</td>\n",
       "      <td>0.011692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.481501</td>\n",
       "      <td>0.050728</td>\n",
       "      <td>10</td>\n",
       "      <td>poly</td>\n",
       "      <td>1</td>\n",
       "      <td>0.804031</td>\n",
       "      <td>0.011860</td>\n",
       "      <td>0.806617</td>\n",
       "      <td>0.011703</td>\n",
       "      <td>0.799754</td>\n",
       "      <td>0.012511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.507810</td>\n",
       "      <td>0.013028</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>1</td>\n",
       "      <td>0.775392</td>\n",
       "      <td>0.009638</td>\n",
       "      <td>0.778519</td>\n",
       "      <td>0.009490</td>\n",
       "      <td>0.767915</td>\n",
       "      <td>0.010497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.734662</td>\n",
       "      <td>0.016433</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.775236</td>\n",
       "      <td>0.037663</td>\n",
       "      <td>0.771524</td>\n",
       "      <td>0.038311</td>\n",
       "      <td>0.760152</td>\n",
       "      <td>0.045879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.638575</td>\n",
       "      <td>0.016797</td>\n",
       "      <td>0.001</td>\n",
       "      <td>poly</td>\n",
       "      <td>1</td>\n",
       "      <td>0.775236</td>\n",
       "      <td>0.037663</td>\n",
       "      <td>0.771524</td>\n",
       "      <td>0.038311</td>\n",
       "      <td>0.760152</td>\n",
       "      <td>0.045879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.555366</td>\n",
       "      <td>0.015870</td>\n",
       "      <td>10</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.763735</td>\n",
       "      <td>0.016420</td>\n",
       "      <td>0.767097</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.754150</td>\n",
       "      <td>0.019560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.564606</td>\n",
       "      <td>0.012050</td>\n",
       "      <td>0.1</td>\n",
       "      <td>poly</td>\n",
       "      <td>1</td>\n",
       "      <td>0.743257</td>\n",
       "      <td>0.009759</td>\n",
       "      <td>0.747050</td>\n",
       "      <td>0.009527</td>\n",
       "      <td>0.730132</td>\n",
       "      <td>0.011063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.602199</td>\n",
       "      <td>0.011221</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.729602</td>\n",
       "      <td>0.016085</td>\n",
       "      <td>0.732094</td>\n",
       "      <td>0.015168</td>\n",
       "      <td>0.710718</td>\n",
       "      <td>0.019369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.729169</td>\n",
       "      <td>0.012296</td>\n",
       "      <td>0.1</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.729776</td>\n",
       "      <td>0.022779</td>\n",
       "      <td>0.725290</td>\n",
       "      <td>0.023189</td>\n",
       "      <td>0.705025</td>\n",
       "      <td>0.028952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.749641</td>\n",
       "      <td>0.018103</td>\n",
       "      <td>0.001</td>\n",
       "      <td>poly</td>\n",
       "      <td>1</td>\n",
       "      <td>0.708965</td>\n",
       "      <td>0.025365</td>\n",
       "      <td>0.704137</td>\n",
       "      <td>0.025793</td>\n",
       "      <td>0.677767</td>\n",
       "      <td>0.034239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.768131</td>\n",
       "      <td>0.039489</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>poly</td>\n",
       "      <td>1</td>\n",
       "      <td>0.661010</td>\n",
       "      <td>0.015462</td>\n",
       "      <td>0.655386</td>\n",
       "      <td>0.015750</td>\n",
       "      <td>0.611629</td>\n",
       "      <td>0.022960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.907105</td>\n",
       "      <td>0.057215</td>\n",
       "      <td>10</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.661010</td>\n",
       "      <td>0.015462</td>\n",
       "      <td>0.655386</td>\n",
       "      <td>0.015750</td>\n",
       "      <td>0.611629</td>\n",
       "      <td>0.022960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.749473</td>\n",
       "      <td>0.019450</td>\n",
       "      <td>0.001</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.642362</td>\n",
       "      <td>0.018880</td>\n",
       "      <td>0.636434</td>\n",
       "      <td>0.019120</td>\n",
       "      <td>0.583581</td>\n",
       "      <td>0.028800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.882051</td>\n",
       "      <td>0.007073</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.624541</td>\n",
       "      <td>0.008177</td>\n",
       "      <td>0.630569</td>\n",
       "      <td>0.008031</td>\n",
       "      <td>0.568826</td>\n",
       "      <td>0.012260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.779166</td>\n",
       "      <td>0.031434</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>poly</td>\n",
       "      <td>1</td>\n",
       "      <td>0.628376</td>\n",
       "      <td>0.014920</td>\n",
       "      <td>0.622213</td>\n",
       "      <td>0.015131</td>\n",
       "      <td>0.562098</td>\n",
       "      <td>0.023875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.890037</td>\n",
       "      <td>0.024159</td>\n",
       "      <td>0.1</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.628376</td>\n",
       "      <td>0.014920</td>\n",
       "      <td>0.622213</td>\n",
       "      <td>0.015131</td>\n",
       "      <td>0.562098</td>\n",
       "      <td>0.023875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.870117</td>\n",
       "      <td>0.030145</td>\n",
       "      <td>0.001</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.603733</td>\n",
       "      <td>0.013557</td>\n",
       "      <td>0.597163</td>\n",
       "      <td>0.013711</td>\n",
       "      <td>0.522031</td>\n",
       "      <td>0.022869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.913531</td>\n",
       "      <td>0.035843</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.598072</td>\n",
       "      <td>0.010008</td>\n",
       "      <td>0.591405</td>\n",
       "      <td>0.010170</td>\n",
       "      <td>0.512619</td>\n",
       "      <td>0.017301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.023179</td>\n",
       "      <td>0.035729</td>\n",
       "      <td>0.1</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.588077</td>\n",
       "      <td>0.008618</td>\n",
       "      <td>0.594688</td>\n",
       "      <td>0.008590</td>\n",
       "      <td>0.511480</td>\n",
       "      <td>0.014462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.954604</td>\n",
       "      <td>0.051549</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.593743</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.587005</td>\n",
       "      <td>0.010096</td>\n",
       "      <td>0.505189</td>\n",
       "      <td>0.017381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.346961</td>\n",
       "      <td>0.085133</td>\n",
       "      <td>0.001</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.561608</td>\n",
       "      <td>0.009330</td>\n",
       "      <td>0.555298</td>\n",
       "      <td>0.009450</td>\n",
       "      <td>0.479979</td>\n",
       "      <td>0.015985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.433271</td>\n",
       "      <td>0.071028</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.558611</td>\n",
       "      <td>0.010616</td>\n",
       "      <td>0.552391</td>\n",
       "      <td>0.010639</td>\n",
       "      <td>0.479210</td>\n",
       "      <td>0.015769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.352339</td>\n",
       "      <td>0.095065</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>poly</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558611</td>\n",
       "      <td>0.010616</td>\n",
       "      <td>0.552391</td>\n",
       "      <td>0.010639</td>\n",
       "      <td>0.479210</td>\n",
       "      <td>0.015769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2.172178</td>\n",
       "      <td>0.331100</td>\n",
       "      <td>10</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.556612</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>0.550470</td>\n",
       "      <td>0.009238</td>\n",
       "      <td>0.479009</td>\n",
       "      <td>0.015861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.524522</td>\n",
       "      <td>0.059162</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.556612</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>0.550470</td>\n",
       "      <td>0.009238</td>\n",
       "      <td>0.479009</td>\n",
       "      <td>0.015861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.390562</td>\n",
       "      <td>0.040672</td>\n",
       "      <td>0.1</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.556612</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>0.550470</td>\n",
       "      <td>0.009238</td>\n",
       "      <td>0.479009</td>\n",
       "      <td>0.015861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.506537</td>\n",
       "      <td>0.051121</td>\n",
       "      <td>0.1</td>\n",
       "      <td>poly</td>\n",
       "      <td>1</td>\n",
       "      <td>0.556612</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>0.550470</td>\n",
       "      <td>0.009238</td>\n",
       "      <td>0.479009</td>\n",
       "      <td>0.015861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1.503333</td>\n",
       "      <td>0.082732</td>\n",
       "      <td>10</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.556612</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>0.550470</td>\n",
       "      <td>0.009238</td>\n",
       "      <td>0.479009</td>\n",
       "      <td>0.015861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2.567426</td>\n",
       "      <td>0.331693</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>1</td>\n",
       "      <td>0.556612</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>0.550470</td>\n",
       "      <td>0.009238</td>\n",
       "      <td>0.479009</td>\n",
       "      <td>0.015861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>4.310553</td>\n",
       "      <td>0.402517</td>\n",
       "      <td>10</td>\n",
       "      <td>poly</td>\n",
       "      <td>1</td>\n",
       "      <td>0.556612</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>0.550470</td>\n",
       "      <td>0.009238</td>\n",
       "      <td>0.479009</td>\n",
       "      <td>0.015861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.480786</td>\n",
       "      <td>0.095592</td>\n",
       "      <td>0.001</td>\n",
       "      <td>poly</td>\n",
       "      <td>1</td>\n",
       "      <td>0.556612</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>0.550470</td>\n",
       "      <td>0.009238</td>\n",
       "      <td>0.479009</td>\n",
       "      <td>0.015861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.548267</td>\n",
       "      <td>0.066738</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533802</td>\n",
       "      <td>0.009456</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.009575</td>\n",
       "      <td>0.470405</td>\n",
       "      <td>0.014151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.444524</td>\n",
       "      <td>0.081937</td>\n",
       "      <td>10</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.533802</td>\n",
       "      <td>0.009456</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.009575</td>\n",
       "      <td>0.470405</td>\n",
       "      <td>0.014151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.390575</td>\n",
       "      <td>0.042122</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.533802</td>\n",
       "      <td>0.009456</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.009575</td>\n",
       "      <td>0.470405</td>\n",
       "      <td>0.014151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.413290</td>\n",
       "      <td>0.085030</td>\n",
       "      <td>0.1</td>\n",
       "      <td>poly</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533802</td>\n",
       "      <td>0.009456</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.009575</td>\n",
       "      <td>0.470405</td>\n",
       "      <td>0.014151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.689478</td>\n",
       "      <td>0.124812</td>\n",
       "      <td>10</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.533802</td>\n",
       "      <td>0.009456</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.009575</td>\n",
       "      <td>0.470405</td>\n",
       "      <td>0.014151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2.411852</td>\n",
       "      <td>0.278008</td>\n",
       "      <td>10</td>\n",
       "      <td>poly</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533802</td>\n",
       "      <td>0.009456</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.009575</td>\n",
       "      <td>0.470405</td>\n",
       "      <td>0.014151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.373106</td>\n",
       "      <td>0.075015</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.533469</td>\n",
       "      <td>0.009155</td>\n",
       "      <td>0.527964</td>\n",
       "      <td>0.009263</td>\n",
       "      <td>0.469897</td>\n",
       "      <td>0.013695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.373751</td>\n",
       "      <td>0.039056</td>\n",
       "      <td>0.1</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.533469</td>\n",
       "      <td>0.009155</td>\n",
       "      <td>0.527964</td>\n",
       "      <td>0.009263</td>\n",
       "      <td>0.469897</td>\n",
       "      <td>0.013695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.275567</td>\n",
       "      <td>0.109274</td>\n",
       "      <td>0.1</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.532471</td>\n",
       "      <td>0.010790</td>\n",
       "      <td>0.526949</td>\n",
       "      <td>0.010946</td>\n",
       "      <td>0.468275</td>\n",
       "      <td>0.016573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.076454</td>\n",
       "      <td>0.092376</td>\n",
       "      <td>0.001</td>\n",
       "      <td>poly</td>\n",
       "      <td>1</td>\n",
       "      <td>0.532471</td>\n",
       "      <td>0.010790</td>\n",
       "      <td>0.526949</td>\n",
       "      <td>0.010946</td>\n",
       "      <td>0.468275</td>\n",
       "      <td>0.016573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.233384</td>\n",
       "      <td>0.158330</td>\n",
       "      <td>0.1</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.500168</td>\n",
       "      <td>0.007110</td>\n",
       "      <td>0.498852</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>0.333393</td>\n",
       "      <td>0.003166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.968407</td>\n",
       "      <td>0.106305</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.495169</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.331167</td>\n",
       "      <td>0.002926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.930269</td>\n",
       "      <td>0.016412</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.495169</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.331167</td>\n",
       "      <td>0.002926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.017893</td>\n",
       "      <td>0.072817</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.495169</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.331167</td>\n",
       "      <td>0.002926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.940708</td>\n",
       "      <td>0.026884</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.495169</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.331167</td>\n",
       "      <td>0.002926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.893800</td>\n",
       "      <td>0.009104</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.495169</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.331167</td>\n",
       "      <td>0.002926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.959597</td>\n",
       "      <td>0.118342</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>poly</td>\n",
       "      <td>1</td>\n",
       "      <td>0.495169</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.331167</td>\n",
       "      <td>0.002926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.977769</td>\n",
       "      <td>0.057515</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.495169</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.331167</td>\n",
       "      <td>0.002926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.080091</td>\n",
       "      <td>0.046137</td>\n",
       "      <td>0.001</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.491842</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.329687</td>\n",
       "      <td>0.000149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.915382</td>\n",
       "      <td>0.021463</td>\n",
       "      <td>0.001</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.491842</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.329687</td>\n",
       "      <td>0.000149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.881033</td>\n",
       "      <td>0.035378</td>\n",
       "      <td>0.001</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.491842</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.329687</td>\n",
       "      <td>0.000149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.932679</td>\n",
       "      <td>0.054660</td>\n",
       "      <td>0.001</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.491842</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.329687</td>\n",
       "      <td>0.000149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.911291</td>\n",
       "      <td>0.074454</td>\n",
       "      <td>0.001</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.491842</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.329687</td>\n",
       "      <td>0.000149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time param_C param_kernel param_gamma  \\\n",
       "52       0.443674      0.009745      10         poly         0.5   \n",
       "41       0.441488      0.011680       1         poly           1   \n",
       "28       0.575507      0.006302     0.1         poly         0.5   \n",
       "53       0.435308      0.006793      10         poly           1   \n",
       "51       0.597121      0.020703      10         poly         0.1   \n",
       "40       0.489205      0.013535       1         poly         0.5   \n",
       "29       0.497620      0.015380     0.1         poly           1   \n",
       "59       0.481501      0.050728      10         poly           1   \n",
       "47       0.507810      0.013028       1         poly           1   \n",
       "39       0.734662      0.016433       1         poly         0.1   \n",
       "17       0.638575      0.016797   0.001         poly           1   \n",
       "58       0.555366      0.015870      10         poly         0.5   \n",
       "35       0.564606      0.012050     0.1         poly           1   \n",
       "46       0.602199      0.011221       1         poly         0.5   \n",
       "34       0.729169      0.012296     0.1         poly         0.5   \n",
       "23       0.749641      0.018103   0.001         poly           1   \n",
       "11       0.768131      0.039489  0.0001         poly           1   \n",
       "57       0.907105      0.057215      10         poly         0.1   \n",
       "16       0.749473      0.019450   0.001         poly         0.5   \n",
       "4        0.882051      0.007073  0.0001         poly         0.5   \n",
       "5        0.779166      0.031434  0.0001         poly           1   \n",
       "27       0.890037      0.024159     0.1         poly         0.1   \n",
       "22       0.870117      0.030145   0.001         poly         0.5   \n",
       "10       0.913531      0.035843  0.0001         poly         0.5   \n",
       "33       1.023179      0.035729     0.1         poly         0.1   \n",
       "45       0.954604      0.051549       1         poly         0.1   \n",
       "19       1.346961      0.085133   0.001         poly         0.5   \n",
       "42       1.433271      0.071028       1         poly         0.1   \n",
       "8        1.352339      0.095065  0.0001         poly           1   \n",
       "55       2.172178      0.331100      10         poly         0.5   \n",
       "43       1.524522      0.059162       1         poly         0.5   \n",
       "31       1.390562      0.040672     0.1         poly         0.5   \n",
       "32       1.506537      0.051121     0.1         poly           1   \n",
       "54       1.503333      0.082732      10         poly         0.1   \n",
       "44       2.567426      0.331693       1         poly           1   \n",
       "56       4.310553      0.402517      10         poly           1   \n",
       "20       1.480786      0.095592   0.001         poly           1   \n",
       "38       1.548267      0.066738       1         poly           1   \n",
       "48       1.444524      0.081937      10         poly         0.1   \n",
       "37       1.390575      0.042122       1         poly         0.5   \n",
       "26       1.413290      0.085030     0.1         poly           1   \n",
       "49       1.689478      0.124812      10         poly         0.5   \n",
       "50       2.411852      0.278008      10         poly           1   \n",
       "36       1.373106      0.075015       1         poly         0.1   \n",
       "25       1.373751      0.039056     0.1         poly         0.5   \n",
       "24       1.275567      0.109274     0.1         poly         0.1   \n",
       "14       1.076454      0.092376   0.001         poly           1   \n",
       "30       1.233384      0.158330     0.1         poly         0.1   \n",
       "1        0.968407      0.106305  0.0001         poly         0.5   \n",
       "9        0.930269      0.016412  0.0001         poly         0.1   \n",
       "7        1.017893      0.072817  0.0001         poly         0.5   \n",
       "6        0.940708      0.026884  0.0001         poly         0.1   \n",
       "3        0.893800      0.009104  0.0001         poly         0.1   \n",
       "2        0.959597      0.118342  0.0001         poly           1   \n",
       "0        0.977769      0.057515  0.0001         poly         0.1   \n",
       "21       1.080091      0.046137   0.001         poly         0.1   \n",
       "18       0.915382      0.021463   0.001         poly         0.1   \n",
       "15       0.881033      0.035378   0.001         poly         0.1   \n",
       "13       0.932679      0.054660   0.001         poly         0.5   \n",
       "12       0.911291      0.074454   0.001         poly         0.1   \n",
       "\n",
       "    mean_test_accuracy  std_test_accuracy  mean_test_recall_macro  \\\n",
       "52            0.811190           0.012137                0.813526   \n",
       "41            0.811190           0.012137                0.813526   \n",
       "28            0.811190           0.012137                0.813526   \n",
       "53            0.810524           0.012841                0.812918   \n",
       "51            0.807360           0.013377                0.809856   \n",
       "40            0.806528           0.013807                0.808921   \n",
       "29            0.805528           0.011005                0.808073   \n",
       "59            0.804031           0.011860                0.806617   \n",
       "47            0.775392           0.009638                0.778519   \n",
       "39            0.775236           0.037663                0.771524   \n",
       "17            0.775236           0.037663                0.771524   \n",
       "58            0.763735           0.016420                0.767097   \n",
       "35            0.743257           0.009759                0.747050   \n",
       "46            0.729602           0.016085                0.732094   \n",
       "34            0.729776           0.022779                0.725290   \n",
       "23            0.708965           0.025365                0.704137   \n",
       "11            0.661010           0.015462                0.655386   \n",
       "57            0.661010           0.015462                0.655386   \n",
       "16            0.642362           0.018880                0.636434   \n",
       "4             0.624541           0.008177                0.630569   \n",
       "5             0.628376           0.014920                0.622213   \n",
       "27            0.628376           0.014920                0.622213   \n",
       "22            0.603733           0.013557                0.597163   \n",
       "10            0.598072           0.010008                0.591405   \n",
       "33            0.588077           0.008618                0.594688   \n",
       "45            0.593743           0.009960                0.587005   \n",
       "19            0.561608           0.009330                0.555298   \n",
       "42            0.558611           0.010616                0.552391   \n",
       "8             0.558611           0.010616                0.552391   \n",
       "55            0.556612           0.009132                0.550470   \n",
       "43            0.556612           0.009132                0.550470   \n",
       "31            0.556612           0.009132                0.550470   \n",
       "32            0.556612           0.009132                0.550470   \n",
       "54            0.556612           0.009132                0.550470   \n",
       "44            0.556612           0.009132                0.550470   \n",
       "56            0.556612           0.009132                0.550470   \n",
       "20            0.556612           0.009132                0.550470   \n",
       "38            0.533802           0.009456                0.528302   \n",
       "48            0.533802           0.009456                0.528302   \n",
       "37            0.533802           0.009456                0.528302   \n",
       "26            0.533802           0.009456                0.528302   \n",
       "49            0.533802           0.009456                0.528302   \n",
       "50            0.533802           0.009456                0.528302   \n",
       "36            0.533469           0.009155                0.527964   \n",
       "25            0.533469           0.009155                0.527964   \n",
       "24            0.532471           0.010790                0.526949   \n",
       "14            0.532471           0.010790                0.526949   \n",
       "30            0.500168           0.007110                0.498852   \n",
       "1             0.495169           0.006583                0.500000   \n",
       "9             0.495169           0.006583                0.500000   \n",
       "7             0.495169           0.006583                0.500000   \n",
       "6             0.495169           0.006583                0.500000   \n",
       "3             0.495169           0.006583                0.500000   \n",
       "2             0.495169           0.006583                0.500000   \n",
       "0             0.495169           0.006583                0.500000   \n",
       "21            0.491842           0.000332                0.500000   \n",
       "18            0.491842           0.000332                0.500000   \n",
       "15            0.491842           0.000332                0.500000   \n",
       "13            0.491842           0.000332                0.500000   \n",
       "12            0.491842           0.000332                0.500000   \n",
       "\n",
       "    std_test_recall_macro  mean_test_f1_macro  std_test_f1_macro  \n",
       "52               0.011979            0.807913           0.012640  \n",
       "41               0.011979            0.807913           0.012640  \n",
       "28               0.011979            0.807913           0.012640  \n",
       "53               0.012617            0.807040           0.013557  \n",
       "51               0.013147            0.803429           0.014293  \n",
       "40               0.013663            0.802867           0.014519  \n",
       "29               0.010842            0.801417           0.011692  \n",
       "59               0.011703            0.799754           0.012511  \n",
       "47               0.009490            0.767915           0.010497  \n",
       "39               0.038311            0.760152           0.045879  \n",
       "17               0.038311            0.760152           0.045879  \n",
       "58               0.016095            0.754150           0.019560  \n",
       "35               0.009527            0.730132           0.011063  \n",
       "46               0.015168            0.710718           0.019369  \n",
       "34               0.023189            0.705025           0.028952  \n",
       "23               0.025793            0.677767           0.034239  \n",
       "11               0.015750            0.611629           0.022960  \n",
       "57               0.015750            0.611629           0.022960  \n",
       "16               0.019120            0.583581           0.028800  \n",
       "4                0.008031            0.568826           0.012260  \n",
       "5                0.015131            0.562098           0.023875  \n",
       "27               0.015131            0.562098           0.023875  \n",
       "22               0.013711            0.522031           0.022869  \n",
       "10               0.010170            0.512619           0.017301  \n",
       "33               0.008590            0.511480           0.014462  \n",
       "45               0.010096            0.505189           0.017381  \n",
       "19               0.009450            0.479979           0.015985  \n",
       "42               0.010639            0.479210           0.015769  \n",
       "8                0.010639            0.479210           0.015769  \n",
       "55               0.009238            0.479009           0.015861  \n",
       "43               0.009238            0.479009           0.015861  \n",
       "31               0.009238            0.479009           0.015861  \n",
       "32               0.009238            0.479009           0.015861  \n",
       "54               0.009238            0.479009           0.015861  \n",
       "44               0.009238            0.479009           0.015861  \n",
       "56               0.009238            0.479009           0.015861  \n",
       "20               0.009238            0.479009           0.015861  \n",
       "38               0.009575            0.470405           0.014151  \n",
       "48               0.009575            0.470405           0.014151  \n",
       "37               0.009575            0.470405           0.014151  \n",
       "26               0.009575            0.470405           0.014151  \n",
       "49               0.009575            0.470405           0.014151  \n",
       "50               0.009575            0.470405           0.014151  \n",
       "36               0.009263            0.469897           0.013695  \n",
       "25               0.009263            0.469897           0.013695  \n",
       "24               0.010946            0.468275           0.016573  \n",
       "14               0.010946            0.468275           0.016573  \n",
       "30               0.000984            0.333393           0.003166  \n",
       "1                0.000000            0.331167           0.002926  \n",
       "9                0.000000            0.331167           0.002926  \n",
       "7                0.000000            0.331167           0.002926  \n",
       "6                0.000000            0.331167           0.002926  \n",
       "3                0.000000            0.331167           0.002926  \n",
       "2                0.000000            0.331167           0.002926  \n",
       "0                0.000000            0.331167           0.002926  \n",
       "21               0.000000            0.329687           0.000149  \n",
       "18               0.000000            0.329687           0.000149  \n",
       "15               0.000000            0.329687           0.000149  \n",
       "13               0.000000            0.329687           0.000149  \n",
       "12               0.000000            0.329687           0.000149  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(svc_model_10CV.cv_results_).loc[:, [\n",
    "    'mean_fit_time',\n",
    "    'std_fit_time',\n",
    "    'param_C',\n",
    "    'param_kernel',\n",
    "    'param_gamma',\n",
    "    'mean_test_accuracy',\n",
    "    'std_test_accuracy',\n",
    "    'mean_test_recall_macro',\n",
    "    'std_test_recall_macro',\n",
    "    'mean_test_f1_macro',\n",
    "    'std_test_f1_macro',\n",
    "]].sort_values(by='mean_test_f1_macro',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USING MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUILDING TRAIN & TEST SETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(data['RSSI']).reshape(-1,1), np.array(data['dist_<_1m']).reshape(-1,1), test_size=data.shape[0]//5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCALE TRAIN & TEST SETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INITIALIZING LISTS OF HYPERPARAMETERS FOR GRIDSEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [2*i for i in range(1,4)]\n",
    "sizes = sizes + [[2*i,2*i] for i in range(1,6)]\n",
    "sizes = sizes + [[2*i, 2*i, 2*i] for i in range (1,6)]\n",
    "\n",
    "alphas = [0, 0.1, 0.01, 0.001]\n",
    "\n",
    "activations = ['logistic', 'relu', 'tanh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8204313752459675\n",
      "{'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': [8, 8, 8]}\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(max_iter=200, solver='adam',random_state=35252)\n",
    "\n",
    "trc = GridSearchCV(estimator=mlp, \n",
    "                   param_grid ={'hidden_layer_sizes': sizes,\n",
    "                                'alpha': alphas,\n",
    "                                'activation': activations},\n",
    "                   scoring=['f1_macro'],\n",
    "                   cv=5,\n",
    "                   n_jobs=-1,\n",
    "                   return_train_score=True,\n",
    "                   refit='f1_macro')\n",
    "\n",
    "mlp_model_5CV = trc.fit(X_train,y_train)\n",
    "print(mlp_model_5CV.best_score_)\n",
    "print(mlp_model_5CV.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>std_test_f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>5.739948</td>\n",
       "      <td>1.223310</td>\n",
       "      <td>relu</td>\n",
       "      <td>[8, 8, 8]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.820431</td>\n",
       "      <td>0.013486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>5.727402</td>\n",
       "      <td>0.943849</td>\n",
       "      <td>relu</td>\n",
       "      <td>[8, 8, 8]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.820431</td>\n",
       "      <td>0.013486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>6.864512</td>\n",
       "      <td>0.489419</td>\n",
       "      <td>relu</td>\n",
       "      <td>[8, 8]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.813192</td>\n",
       "      <td>0.010815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>4.590061</td>\n",
       "      <td>0.905075</td>\n",
       "      <td>relu</td>\n",
       "      <td>[8, 8, 8]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812251</td>\n",
       "      <td>0.017909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>6.039159</td>\n",
       "      <td>0.209426</td>\n",
       "      <td>relu</td>\n",
       "      <td>[8, 8]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.811463</td>\n",
       "      <td>0.008831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>6.749181</td>\n",
       "      <td>0.395803</td>\n",
       "      <td>tanh</td>\n",
       "      <td>[4, 4, 4]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.796988</td>\n",
       "      <td>0.017086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>5.505753</td>\n",
       "      <td>0.576609</td>\n",
       "      <td>tanh</td>\n",
       "      <td>[6, 6, 6]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.796756</td>\n",
       "      <td>0.015086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>6.182691</td>\n",
       "      <td>0.086413</td>\n",
       "      <td>tanh</td>\n",
       "      <td>[8, 8]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.794992</td>\n",
       "      <td>0.016192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>8.118220</td>\n",
       "      <td>0.910709</td>\n",
       "      <td>tanh</td>\n",
       "      <td>[8, 8]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.794992</td>\n",
       "      <td>0.016192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.242777</td>\n",
       "      <td>0.112865</td>\n",
       "      <td>tanh</td>\n",
       "      <td>[8, 8]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.794992</td>\n",
       "      <td>0.016192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time param_activation param_hidden_layer_sizes  \\\n",
       "89        5.739948      1.223310             relu                [8, 8, 8]   \n",
       "102       5.727402      0.943849             relu                [8, 8, 8]   \n",
       "71        6.864512      0.489419             relu                   [8, 8]   \n",
       "63        4.590061      0.905075             relu                [8, 8, 8]   \n",
       "58        6.039159      0.209426             relu                   [8, 8]   \n",
       "..             ...           ...              ...                      ...   \n",
       "113       6.749181      0.395803             tanh                [4, 4, 4]   \n",
       "127       5.505753      0.576609             tanh                [6, 6, 6]   \n",
       "149       6.182691      0.086413             tanh                   [8, 8]   \n",
       "110       8.118220      0.910709             tanh                   [8, 8]   \n",
       "136       6.242777      0.112865             tanh                   [8, 8]   \n",
       "\n",
       "    param_alpha  mean_test_f1_macro  std_test_f1_macro  \n",
       "89         0.01            0.820431           0.013486  \n",
       "102       0.001            0.820431           0.013486  \n",
       "71          0.1            0.813192           0.010815  \n",
       "63            0            0.812251           0.017909  \n",
       "58            0            0.811463           0.008831  \n",
       "..          ...                 ...                ...  \n",
       "113           0            0.796988           0.017086  \n",
       "127         0.1            0.796756           0.015086  \n",
       "149       0.001            0.794992           0.016192  \n",
       "110           0            0.794992           0.016192  \n",
       "136        0.01            0.794992           0.016192  \n",
       "\n",
       "[156 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(mlp_model_5CV.cv_results_).loc[:, [\n",
    "    'mean_fit_time',\n",
    "    'std_fit_time',\n",
    "    'param_activation',\n",
    "    'param_hidden_layer_sizes',\n",
    "    'param_alpha',\n",
    "    'mean_test_f1_macro',\n",
    "    'std_test_f1_macro',\n",
    "]].sort_values(by='mean_test_f1_macro',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RE-TRAIN WITH THE BEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.01, hidden_layer_sizes=(8, 8, 8))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_best = MLPClassifier(hidden_layer_sizes=(8,8,8), alpha=0.01, activation='relu', max_iter=200, solver='adam')\n",
    "mlp_best.fit(X_train,y_train)\n",
    "\n",
    "#scores = cross_val_score(mlp_best, X_train, y_train, cv=5)\n",
    "#scores_recall = cross_val_score(mlp_best, X_train, y_train, cv=5, scoring='recall_macro')\n",
    "#scores_f_score = cross_val_score(mlp_best, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "#[np.mean(scores),np.mean(scores_recall),np.mean(scores_f_score)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST SET SCORE EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.74      0.81       929\n",
      "           1       0.77      0.92      0.84       872\n",
      "\n",
      "    accuracy                           0.83      1801\n",
      "   macro avg       0.84      0.83      0.82      1801\n",
      "weighted avg       0.84      0.83      0.82      1801\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = mlp_best.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
